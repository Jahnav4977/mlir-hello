// -----// IR Dump After {anonymous}::MxToTosaLowerPass () //----- //
module {
  func.func @test_linear(%arg0: tensor<5x2xf32>, %arg1: tensor<3x2xf32>) -> tensor<5x3xf32> attributes {llvm.emit_c_interface} {
    %0 = "tosa.const"() <{value = dense<[1, 0]> : tensor<2xi32>}> : () -> tensor<2xi32>
    %1 = tosa.transpose %arg1, %0 : (tensor<3x2xf32>, tensor<2xi32>) -> tensor<2x3xf32>
    %2 = tosa.reshape %arg0 {new_shape = array<i64: 1, 5, 2>} : (tensor<5x2xf32>) -> tensor<1x5x2xf32>
    %3 = tosa.reshape %1 {new_shape = array<i64: 1, 2, 3>} : (tensor<2x3xf32>) -> tensor<1x2x3xf32>
    %4 = tosa.matmul %2, %3 : (tensor<1x5x2xf32>, tensor<1x2x3xf32>) -> tensor<1x5x3xf32>
    %5 = tosa.reshape %4 {new_shape = array<i64: 5, 3>} : (tensor<1x5x3xf32>) -> tensor<5x3xf32>
    %cast = tensor.cast %5 : tensor<5x3xf32> to tensor<5x3xf32>
    return %cast : tensor<5x3xf32>
  }
}


// -----// IR Dump After TosaToArith (tosa-to-arith) //----- //
module {
  func.func @test_linear(%arg0: tensor<5x2xf32>, %arg1: tensor<3x2xf32>) -> tensor<5x3xf32> attributes {llvm.emit_c_interface} {
    %cst = arith.constant dense<[1, 0]> : tensor<2xi32>
    %0 = tosa.transpose %arg1, %cst : (tensor<3x2xf32>, tensor<2xi32>) -> tensor<2x3xf32>
    %1 = tosa.reshape %arg0 {new_shape = array<i64: 1, 5, 2>} : (tensor<5x2xf32>) -> tensor<1x5x2xf32>
    %2 = tosa.reshape %0 {new_shape = array<i64: 1, 2, 3>} : (tensor<2x3xf32>) -> tensor<1x2x3xf32>
    %3 = tosa.matmul %1, %2 : (tensor<1x5x2xf32>, tensor<1x2x3xf32>) -> tensor<1x5x3xf32>
    %4 = tosa.reshape %3 {new_shape = array<i64: 5, 3>} : (tensor<1x5x3xf32>) -> tensor<5x3xf32>
    return %4 : tensor<5x3xf32>
  }
}


// -----// IR Dump After TosaToTensor (tosa-to-tensor) //----- //
module {
  func.func @test_linear(%arg0: tensor<5x2xf32>, %arg1: tensor<3x2xf32>) -> tensor<5x3xf32> attributes {llvm.emit_c_interface} {
    %cst = arith.constant dense<[1, 0]> : tensor<2xi32>
    %0 = tosa.transpose %arg1, %cst : (tensor<3x2xf32>, tensor<2xi32>) -> tensor<2x3xf32>
    %expanded = tensor.expand_shape %arg0 [[0, 1], [2]] output_shape [1, 5, 2] : tensor<5x2xf32> into tensor<1x5x2xf32>
    %expanded_0 = tensor.expand_shape %0 [[0, 1], [2]] output_shape [1, 2, 3] : tensor<2x3xf32> into tensor<1x2x3xf32>
    %1 = tosa.matmul %expanded, %expanded_0 : (tensor<1x5x2xf32>, tensor<1x2x3xf32>) -> tensor<1x5x3xf32>
    %collapsed = tensor.collapse_shape %1 [[0, 1], [2]] : tensor<1x5x3xf32> into tensor<5x3xf32>
    return %collapsed : tensor<5x3xf32>
  }
}


// -----// IR Dump After TosaToLinalgNamed (tosa-to-linalg-named) //----- //
func.func @test_linear(%arg0: tensor<5x2xf32>, %arg1: tensor<3x2xf32>) -> tensor<5x3xf32> attributes {llvm.emit_c_interface} {
  %cst = arith.constant dense<[1, 0]> : tensor<2xi32>
  %0 = tensor.empty() : tensor<2x3xf32>
  %transposed = linalg.transpose ins(%arg1 : tensor<3x2xf32>) outs(%0 : tensor<2x3xf32>) permutation = [1, 0] 
  %expanded = tensor.expand_shape %arg0 [[0, 1], [2]] output_shape [1, 5, 2] : tensor<5x2xf32> into tensor<1x5x2xf32>
  %expanded_0 = tensor.expand_shape %transposed [[0, 1], [2]] output_shape [1, 2, 3] : tensor<2x3xf32> into tensor<1x2x3xf32>
  %cst_1 = arith.constant 0.000000e+00 : f32
  %1 = tensor.empty() : tensor<1x5x3xf32>
  %2 = linalg.fill ins(%cst_1 : f32) outs(%1 : tensor<1x5x3xf32>) -> tensor<1x5x3xf32>
  %3 = linalg.batch_matmul ins(%expanded, %expanded_0 : tensor<1x5x2xf32>, tensor<1x2x3xf32>) outs(%2 : tensor<1x5x3xf32>) -> tensor<1x5x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1], [2]] : tensor<1x5x3xf32> into tensor<5x3xf32>
  return %collapsed : tensor<5x3xf32>
}

// -----// IR Dump After TosaToLinalg (tosa-to-linalg) //----- //
func.func @test_linear(%arg0: tensor<5x2xf32>, %arg1: tensor<3x2xf32>) -> tensor<5x3xf32> attributes {llvm.emit_c_interface} {
  %cst = arith.constant dense<[1, 0]> : tensor<2xi32>
  %0 = tensor.empty() : tensor<2x3xf32>
  %transposed = linalg.transpose ins(%arg1 : tensor<3x2xf32>) outs(%0 : tensor<2x3xf32>) permutation = [1, 0] 
  %expanded = tensor.expand_shape %arg0 [[0, 1], [2]] output_shape [1, 5, 2] : tensor<5x2xf32> into tensor<1x5x2xf32>
  %expanded_0 = tensor.expand_shape %transposed [[0, 1], [2]] output_shape [1, 2, 3] : tensor<2x3xf32> into tensor<1x2x3xf32>
  %cst_1 = arith.constant 0.000000e+00 : f32
  %1 = tensor.empty() : tensor<1x5x3xf32>
  %2 = linalg.fill ins(%cst_1 : f32) outs(%1 : tensor<1x5x3xf32>) -> tensor<1x5x3xf32>
  %3 = linalg.batch_matmul ins(%expanded, %expanded_0 : tensor<1x5x2xf32>, tensor<1x2x3xf32>) outs(%2 : tensor<1x5x3xf32>) -> tensor<1x5x3xf32>
  %collapsed = tensor.collapse_shape %3 [[0, 1], [2]] : tensor<1x5x3xf32> into tensor<5x3xf32>
  return %collapsed : tensor<5x3xf32>
}

// -----// IR Dump After OneShotBufferize (one-shot-bufferize) //----- //
module {
  memref.global "private" constant @__constant_2xi32 : memref<2xi32> = dense<[1, 0]> {alignment = 64 : i64}
  func.func @test_linear(%arg0: tensor<5x2xf32>, %arg1: tensor<3x2xf32>) -> tensor<5x3xf32> attributes {llvm.emit_c_interface} {
    %0 = bufferization.to_memref %arg0 : memref<5x2xf32, strided<[?, ?], offset: ?>>
    %1 = bufferization.to_memref %arg1 : memref<3x2xf32, strided<[?, ?], offset: ?>>
    %2 = memref.get_global @__constant_2xi32 : memref<2xi32>
    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2x3xf32>
    linalg.transpose ins(%1 : memref<3x2xf32, strided<[?, ?], offset: ?>>) outs(%alloc : memref<2x3xf32>) permutation = [1, 0] 
    %expand_shape = memref.expand_shape %0 [[0, 1], [2]] output_shape [1, 5, 2] : memref<5x2xf32, strided<[?, ?], offset: ?>> into memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
    %expand_shape_0 = memref.expand_shape %alloc [[0, 1], [2]] output_shape [1, 2, 3] : memref<2x3xf32> into memref<1x2x3xf32>
    %cst = arith.constant 0.000000e+00 : f32
    %alloc_1 = memref.alloc() {alignment = 64 : i64} : memref<1x5x3xf32>
    linalg.fill ins(%cst : f32) outs(%alloc_1 : memref<1x5x3xf32>)
    linalg.batch_matmul ins(%expand_shape, %expand_shape_0 : memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>, memref<1x2x3xf32>) outs(%alloc_1 : memref<1x5x3xf32>)
    %collapse_shape = memref.collapse_shape %alloc_1 [[0, 1], [2]] : memref<1x5x3xf32> into memref<5x3xf32>
    %3 = bufferization.to_tensor %collapse_shape : memref<5x3xf32>
    return %3 : tensor<5x3xf32>
  }
}


// -----// IR Dump After FuncBufferize (func-bufferize) //----- //
module {
  memref.global "private" constant @__constant_2xi32 : memref<2xi32> = dense<[1, 0]> {alignment = 64 : i64}
  func.func @test_linear(%arg0: memref<5x2xf32>, %arg1: memref<3x2xf32>) -> memref<5x3xf32> attributes {llvm.emit_c_interface} {
    %0 = bufferization.to_tensor %arg1 : memref<3x2xf32>
    %1 = bufferization.to_tensor %arg0 : memref<5x2xf32>
    %2 = bufferization.to_memref %1 : memref<5x2xf32, strided<[?, ?], offset: ?>>
    %3 = bufferization.to_memref %0 : memref<3x2xf32, strided<[?, ?], offset: ?>>
    %4 = memref.get_global @__constant_2xi32 : memref<2xi32>
    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2x3xf32>
    linalg.transpose ins(%3 : memref<3x2xf32, strided<[?, ?], offset: ?>>) outs(%alloc : memref<2x3xf32>) permutation = [1, 0] 
    %expand_shape = memref.expand_shape %2 [[0, 1], [2]] output_shape [1, 5, 2] : memref<5x2xf32, strided<[?, ?], offset: ?>> into memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
    %expand_shape_0 = memref.expand_shape %alloc [[0, 1], [2]] output_shape [1, 2, 3] : memref<2x3xf32> into memref<1x2x3xf32>
    %cst = arith.constant 0.000000e+00 : f32
    %alloc_1 = memref.alloc() {alignment = 64 : i64} : memref<1x5x3xf32>
    linalg.fill ins(%cst : f32) outs(%alloc_1 : memref<1x5x3xf32>)
    linalg.batch_matmul ins(%expand_shape, %expand_shape_0 : memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>, memref<1x2x3xf32>) outs(%alloc_1 : memref<1x5x3xf32>)
    %collapse_shape = memref.collapse_shape %alloc_1 [[0, 1], [2]] : memref<1x5x3xf32> into memref<5x3xf32>
    %5 = bufferization.to_tensor %collapse_shape : memref<5x3xf32>
    %6 = bufferization.to_memref %5 : memref<5x3xf32>
    return %6 : memref<5x3xf32>
  }
}


// -----// IR Dump After ConvertLinalgToAffineLoopsPass (convert-linalg-to-affine-loops) //----- //
func.func @test_linear(%arg0: memref<5x2xf32>, %arg1: memref<3x2xf32>) -> memref<5x3xf32> attributes {llvm.emit_c_interface} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = bufferization.to_tensor %arg1 : memref<3x2xf32>
  %1 = bufferization.to_tensor %arg0 : memref<5x2xf32>
  %2 = bufferization.to_memref %1 : memref<5x2xf32, strided<[?, ?], offset: ?>>
  %3 = bufferization.to_memref %0 : memref<3x2xf32, strided<[?, ?], offset: ?>>
  %alloc = memref.alloc() {alignment = 64 : i64} : memref<2x3xf32>
  affine.for %arg2 = 0 to 2 {
    affine.for %arg3 = 0 to 3 {
      %4 = affine.load %3[%arg3, %arg2] : memref<3x2xf32, strided<[?, ?], offset: ?>>
      affine.store %4, %alloc[%arg2, %arg3] : memref<2x3xf32>
    }
  }
  %expand_shape = memref.expand_shape %2 [[0, 1], [2]] output_shape [1, 5, 2] : memref<5x2xf32, strided<[?, ?], offset: ?>> into memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
  %expand_shape_0 = memref.expand_shape %alloc [[0, 1], [2]] output_shape [1, 2, 3] : memref<2x3xf32> into memref<1x2x3xf32>
  %alloc_1 = memref.alloc() {alignment = 64 : i64} : memref<1x5x3xf32>
  affine.for %arg2 = 0 to 1 {
    affine.for %arg3 = 0 to 5 {
      affine.for %arg4 = 0 to 3 {
        affine.store %cst, %alloc_1[%arg2, %arg3, %arg4] : memref<1x5x3xf32>
      }
    }
  }
  affine.for %arg2 = 0 to 1 {
    affine.for %arg3 = 0 to 5 {
      affine.for %arg4 = 0 to 3 {
        affine.for %arg5 = 0 to 2 {
          %4 = affine.load %expand_shape[%arg2, %arg3, %arg5] : memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
          %5 = affine.load %expand_shape_0[%arg2, %arg5, %arg4] : memref<1x2x3xf32>
          %6 = affine.load %alloc_1[%arg2, %arg3, %arg4] : memref<1x5x3xf32>
          %7 = arith.mulf %4, %5 : f32
          %8 = arith.addf %6, %7 : f32
          affine.store %8, %alloc_1[%arg2, %arg3, %arg4] : memref<1x5x3xf32>
        }
      }
    }
  }
  %collapse_shape = memref.collapse_shape %alloc_1 [[0, 1], [2]] : memref<1x5x3xf32> into memref<5x3xf32>
  return %collapse_shape : memref<5x3xf32>
}

// -----// IR Dump After ConvertAffineToStandard (lower-affine) //----- //
func.func @test_linear(%arg0: memref<5x2xf32>, %arg1: memref<3x2xf32>) -> memref<5x3xf32> attributes {llvm.emit_c_interface} {
  %cst = arith.constant 0.000000e+00 : f32
  %0 = bufferization.to_tensor %arg1 : memref<3x2xf32>
  %1 = bufferization.to_tensor %arg0 : memref<5x2xf32>
  %2 = bufferization.to_memref %1 : memref<5x2xf32, strided<[?, ?], offset: ?>>
  %3 = bufferization.to_memref %0 : memref<3x2xf32, strided<[?, ?], offset: ?>>
  %alloc = memref.alloc() {alignment = 64 : i64} : memref<2x3xf32>
  %c0 = arith.constant 0 : index
  %c2 = arith.constant 2 : index
  %c1 = arith.constant 1 : index
  scf.for %arg2 = %c0 to %c2 step %c1 {
    %c0_8 = arith.constant 0 : index
    %c3 = arith.constant 3 : index
    %c1_9 = arith.constant 1 : index
    scf.for %arg3 = %c0_8 to %c3 step %c1_9 {
      %4 = memref.load %3[%arg3, %arg2] : memref<3x2xf32, strided<[?, ?], offset: ?>>
      memref.store %4, %alloc[%arg2, %arg3] : memref<2x3xf32>
    }
  }
  %expand_shape = memref.expand_shape %2 [[0, 1], [2]] output_shape [1, 5, 2] : memref<5x2xf32, strided<[?, ?], offset: ?>> into memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
  %expand_shape_0 = memref.expand_shape %alloc [[0, 1], [2]] output_shape [1, 2, 3] : memref<2x3xf32> into memref<1x2x3xf32>
  %alloc_1 = memref.alloc() {alignment = 64 : i64} : memref<1x5x3xf32>
  %c0_2 = arith.constant 0 : index
  %c1_3 = arith.constant 1 : index
  %c1_4 = arith.constant 1 : index
  scf.for %arg2 = %c0_2 to %c1_3 step %c1_4 {
    %c0_8 = arith.constant 0 : index
    %c5 = arith.constant 5 : index
    %c1_9 = arith.constant 1 : index
    scf.for %arg3 = %c0_8 to %c5 step %c1_9 {
      %c0_10 = arith.constant 0 : index
      %c3 = arith.constant 3 : index
      %c1_11 = arith.constant 1 : index
      scf.for %arg4 = %c0_10 to %c3 step %c1_11 {
        memref.store %cst, %alloc_1[%arg2, %arg3, %arg4] : memref<1x5x3xf32>
      }
    }
  }
  %c0_5 = arith.constant 0 : index
  %c1_6 = arith.constant 1 : index
  %c1_7 = arith.constant 1 : index
  scf.for %arg2 = %c0_5 to %c1_6 step %c1_7 {
    %c0_8 = arith.constant 0 : index
    %c5 = arith.constant 5 : index
    %c1_9 = arith.constant 1 : index
    scf.for %arg3 = %c0_8 to %c5 step %c1_9 {
      %c0_10 = arith.constant 0 : index
      %c3 = arith.constant 3 : index
      %c1_11 = arith.constant 1 : index
      scf.for %arg4 = %c0_10 to %c3 step %c1_11 {
        %c0_12 = arith.constant 0 : index
        %c2_13 = arith.constant 2 : index
        %c1_14 = arith.constant 1 : index
        scf.for %arg5 = %c0_12 to %c2_13 step %c1_14 {
          %4 = memref.load %expand_shape[%arg2, %arg3, %arg5] : memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
          %5 = memref.load %expand_shape_0[%arg2, %arg5, %arg4] : memref<1x2x3xf32>
          %6 = memref.load %alloc_1[%arg2, %arg3, %arg4] : memref<1x5x3xf32>
          %7 = arith.mulf %4, %5 : f32
          %8 = arith.addf %6, %7 : f32
          memref.store %8, %alloc_1[%arg2, %arg3, %arg4] : memref<1x5x3xf32>
        }
      }
    }
  }
  %collapse_shape = memref.collapse_shape %alloc_1 [[0, 1], [2]] : memref<1x5x3xf32> into memref<5x3xf32>
  return %collapse_shape : memref<5x3xf32>
}

// -----// IR Dump After SCFToControlFlow (convert-scf-to-cf) //----- //
module {
  memref.global "private" constant @__constant_2xi32 : memref<2xi32> = dense<[1, 0]> {alignment = 64 : i64}
  func.func @test_linear(%arg0: memref<5x2xf32>, %arg1: memref<3x2xf32>) -> memref<5x3xf32> attributes {llvm.emit_c_interface} {
    %cst = arith.constant 0.000000e+00 : f32
    %0 = bufferization.to_tensor %arg1 : memref<3x2xf32>
    %1 = bufferization.to_tensor %arg0 : memref<5x2xf32>
    %2 = bufferization.to_memref %1 : memref<5x2xf32, strided<[?, ?], offset: ?>>
    %3 = bufferization.to_memref %0 : memref<3x2xf32, strided<[?, ?], offset: ?>>
    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2x3xf32>
    %c0 = arith.constant 0 : index
    %c2 = arith.constant 2 : index
    %c1 = arith.constant 1 : index
    cf.br ^bb1(%c0 : index)
  ^bb1(%4: index):  // 2 preds: ^bb0, ^bb5
    %5 = arith.cmpi slt, %4, %c2 : index
    cf.cond_br %5, ^bb2, ^bb6
  ^bb2:  // pred: ^bb1
    %c0_0 = arith.constant 0 : index
    %c3 = arith.constant 3 : index
    %c1_1 = arith.constant 1 : index
    cf.br ^bb3(%c0_0 : index)
  ^bb3(%6: index):  // 2 preds: ^bb2, ^bb4
    %7 = arith.cmpi slt, %6, %c3 : index
    cf.cond_br %7, ^bb4, ^bb5
  ^bb4:  // pred: ^bb3
    %8 = memref.load %3[%6, %4] : memref<3x2xf32, strided<[?, ?], offset: ?>>
    memref.store %8, %alloc[%4, %6] : memref<2x3xf32>
    %9 = arith.addi %6, %c1_1 : index
    cf.br ^bb3(%9 : index)
  ^bb5:  // pred: ^bb3
    %10 = arith.addi %4, %c1 : index
    cf.br ^bb1(%10 : index)
  ^bb6:  // pred: ^bb1
    %expand_shape = memref.expand_shape %2 [[0, 1], [2]] output_shape [1, 5, 2] : memref<5x2xf32, strided<[?, ?], offset: ?>> into memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
    %expand_shape_2 = memref.expand_shape %alloc [[0, 1], [2]] output_shape [1, 2, 3] : memref<2x3xf32> into memref<1x2x3xf32>
    %alloc_3 = memref.alloc() {alignment = 64 : i64} : memref<1x5x3xf32>
    %c0_4 = arith.constant 0 : index
    %c1_5 = arith.constant 1 : index
    %c1_6 = arith.constant 1 : index
    cf.br ^bb7(%c0_4 : index)
  ^bb7(%11: index):  // 2 preds: ^bb6, ^bb14
    %12 = arith.cmpi slt, %11, %c1_5 : index
    cf.cond_br %12, ^bb8, ^bb15
  ^bb8:  // pred: ^bb7
    %c0_7 = arith.constant 0 : index
    %c5 = arith.constant 5 : index
    %c1_8 = arith.constant 1 : index
    cf.br ^bb9(%c0_7 : index)
  ^bb9(%13: index):  // 2 preds: ^bb8, ^bb13
    %14 = arith.cmpi slt, %13, %c5 : index
    cf.cond_br %14, ^bb10, ^bb14
  ^bb10:  // pred: ^bb9
    %c0_9 = arith.constant 0 : index
    %c3_10 = arith.constant 3 : index
    %c1_11 = arith.constant 1 : index
    cf.br ^bb11(%c0_9 : index)
  ^bb11(%15: index):  // 2 preds: ^bb10, ^bb12
    %16 = arith.cmpi slt, %15, %c3_10 : index
    cf.cond_br %16, ^bb12, ^bb13
  ^bb12:  // pred: ^bb11
    memref.store %cst, %alloc_3[%11, %13, %15] : memref<1x5x3xf32>
    %17 = arith.addi %15, %c1_11 : index
    cf.br ^bb11(%17 : index)
  ^bb13:  // pred: ^bb11
    %18 = arith.addi %13, %c1_8 : index
    cf.br ^bb9(%18 : index)
  ^bb14:  // pred: ^bb9
    %19 = arith.addi %11, %c1_6 : index
    cf.br ^bb7(%19 : index)
  ^bb15:  // pred: ^bb7
    %c0_12 = arith.constant 0 : index
    %c1_13 = arith.constant 1 : index
    %c1_14 = arith.constant 1 : index
    cf.br ^bb16(%c0_12 : index)
  ^bb16(%20: index):  // 2 preds: ^bb15, ^bb26
    %21 = arith.cmpi slt, %20, %c1_13 : index
    cf.cond_br %21, ^bb17, ^bb27
  ^bb17:  // pred: ^bb16
    %c0_15 = arith.constant 0 : index
    %c5_16 = arith.constant 5 : index
    %c1_17 = arith.constant 1 : index
    cf.br ^bb18(%c0_15 : index)
  ^bb18(%22: index):  // 2 preds: ^bb17, ^bb25
    %23 = arith.cmpi slt, %22, %c5_16 : index
    cf.cond_br %23, ^bb19, ^bb26
  ^bb19:  // pred: ^bb18
    %c0_18 = arith.constant 0 : index
    %c3_19 = arith.constant 3 : index
    %c1_20 = arith.constant 1 : index
    cf.br ^bb20(%c0_18 : index)
  ^bb20(%24: index):  // 2 preds: ^bb19, ^bb24
    %25 = arith.cmpi slt, %24, %c3_19 : index
    cf.cond_br %25, ^bb21, ^bb25
  ^bb21:  // pred: ^bb20
    %c0_21 = arith.constant 0 : index
    %c2_22 = arith.constant 2 : index
    %c1_23 = arith.constant 1 : index
    cf.br ^bb22(%c0_21 : index)
  ^bb22(%26: index):  // 2 preds: ^bb21, ^bb23
    %27 = arith.cmpi slt, %26, %c2_22 : index
    cf.cond_br %27, ^bb23, ^bb24
  ^bb23:  // pred: ^bb22
    %28 = memref.load %expand_shape[%20, %22, %26] : memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
    %29 = memref.load %expand_shape_2[%20, %26, %24] : memref<1x2x3xf32>
    %30 = memref.load %alloc_3[%20, %22, %24] : memref<1x5x3xf32>
    %31 = arith.mulf %28, %29 : f32
    %32 = arith.addf %30, %31 : f32
    memref.store %32, %alloc_3[%20, %22, %24] : memref<1x5x3xf32>
    %33 = arith.addi %26, %c1_23 : index
    cf.br ^bb22(%33 : index)
  ^bb24:  // pred: ^bb22
    %34 = arith.addi %24, %c1_20 : index
    cf.br ^bb20(%34 : index)
  ^bb25:  // pred: ^bb20
    %35 = arith.addi %22, %c1_17 : index
    cf.br ^bb18(%35 : index)
  ^bb26:  // pred: ^bb18
    %36 = arith.addi %20, %c1_14 : index
    cf.br ^bb16(%36 : index)
  ^bb27:  // pred: ^bb16
    %collapse_shape = memref.collapse_shape %alloc_3 [[0, 1], [2]] : memref<1x5x3xf32> into memref<5x3xf32>
    return %collapse_shape : memref<5x3xf32>
  }
}


// -----// IR Dump After Canonicalizer (canonicalize) //----- //
module {
  memref.global "private" constant @__constant_2xi32 : memref<2xi32> = dense<[1, 0]> {alignment = 64 : i64}
  func.func @test_linear(%arg0: memref<5x2xf32>, %arg1: memref<3x2xf32>) -> memref<5x3xf32> attributes {llvm.emit_c_interface} {
    %c5 = arith.constant 5 : index
    %c3 = arith.constant 3 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %cast = memref.cast %arg0 : memref<5x2xf32> to memref<5x2xf32, strided<[?, ?], offset: ?>>
    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2x3xf32>
    cf.br ^bb1(%c0 : index)
  ^bb1(%0: index):  // 2 preds: ^bb0, ^bb4
    %1 = arith.cmpi slt, %0, %c2 : index
    cf.cond_br %1, ^bb2(%c0 : index), ^bb5
  ^bb2(%2: index):  // 2 preds: ^bb1, ^bb3
    %3 = arith.cmpi slt, %2, %c3 : index
    cf.cond_br %3, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %4 = memref.load %arg1[%2, %0] : memref<3x2xf32>
    memref.store %4, %alloc[%0, %2] : memref<2x3xf32>
    %5 = arith.addi %2, %c1 : index
    cf.br ^bb2(%5 : index)
  ^bb4:  // pred: ^bb2
    %6 = arith.addi %0, %c1 : index
    cf.br ^bb1(%6 : index)
  ^bb5:  // pred: ^bb1
    %expand_shape = memref.expand_shape %cast [[0, 1], [2]] output_shape [1, 5, 2] : memref<5x2xf32, strided<[?, ?], offset: ?>> into memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
    %expand_shape_0 = memref.expand_shape %alloc [[0, 1], [2]] output_shape [1, 2, 3] : memref<2x3xf32> into memref<1x2x3xf32>
    %alloc_1 = memref.alloc() {alignment = 64 : i64} : memref<1x5x3xf32>
    cf.br ^bb6(%c0 : index)
  ^bb6(%7: index):  // 2 preds: ^bb5, ^bb11
    %8 = arith.cmpi slt, %7, %c1 : index
    cf.cond_br %8, ^bb7(%c0 : index), ^bb12(%c0 : index)
  ^bb7(%9: index):  // 2 preds: ^bb6, ^bb10
    %10 = arith.cmpi slt, %9, %c5 : index
    cf.cond_br %10, ^bb8(%c0 : index), ^bb11
  ^bb8(%11: index):  // 2 preds: ^bb7, ^bb9
    %12 = arith.cmpi slt, %11, %c3 : index
    cf.cond_br %12, ^bb9, ^bb10
  ^bb9:  // pred: ^bb8
    memref.store %cst, %alloc_1[%7, %9, %11] : memref<1x5x3xf32>
    %13 = arith.addi %11, %c1 : index
    cf.br ^bb8(%13 : index)
  ^bb10:  // pred: ^bb8
    %14 = arith.addi %9, %c1 : index
    cf.br ^bb7(%14 : index)
  ^bb11:  // pred: ^bb7
    %15 = arith.addi %7, %c1 : index
    cf.br ^bb6(%15 : index)
  ^bb12(%16: index):  // 2 preds: ^bb6, ^bb19
    %17 = arith.cmpi slt, %16, %c1 : index
    cf.cond_br %17, ^bb13(%c0 : index), ^bb20
  ^bb13(%18: index):  // 2 preds: ^bb12, ^bb18
    %19 = arith.cmpi slt, %18, %c5 : index
    cf.cond_br %19, ^bb14(%c0 : index), ^bb19
  ^bb14(%20: index):  // 2 preds: ^bb13, ^bb17
    %21 = arith.cmpi slt, %20, %c3 : index
    cf.cond_br %21, ^bb15(%c0 : index), ^bb18
  ^bb15(%22: index):  // 2 preds: ^bb14, ^bb16
    %23 = arith.cmpi slt, %22, %c2 : index
    cf.cond_br %23, ^bb16, ^bb17
  ^bb16:  // pred: ^bb15
    %24 = memref.load %expand_shape[%16, %18, %22] : memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
    %25 = memref.load %expand_shape_0[%16, %22, %20] : memref<1x2x3xf32>
    %26 = memref.load %alloc_1[%16, %18, %20] : memref<1x5x3xf32>
    %27 = arith.mulf %24, %25 : f32
    %28 = arith.addf %26, %27 : f32
    memref.store %28, %alloc_1[%16, %18, %20] : memref<1x5x3xf32>
    %29 = arith.addi %22, %c1 : index
    cf.br ^bb15(%29 : index)
  ^bb17:  // pred: ^bb15
    %30 = arith.addi %20, %c1 : index
    cf.br ^bb14(%30 : index)
  ^bb18:  // pred: ^bb14
    %31 = arith.addi %18, %c1 : index
    cf.br ^bb13(%31 : index)
  ^bb19:  // pred: ^bb13
    %32 = arith.addi %16, %c1 : index
    cf.br ^bb12(%32 : index)
  ^bb20:  // pred: ^bb12
    %collapse_shape = memref.collapse_shape %alloc_1 [[0, 1], [2]] : memref<1x5x3xf32> into memref<5x3xf32>
    return %collapse_shape : memref<5x3xf32>
  }
}


// -----// IR Dump After ExpandStridedMetadata (expand-strided-metadata) //----- //
module {
  memref.global "private" constant @__constant_2xi32 : memref<2xi32> = dense<[1, 0]> {alignment = 64 : i64}
  func.func @test_linear(%arg0: memref<5x2xf32>, %arg1: memref<3x2xf32>) -> memref<5x3xf32> attributes {llvm.emit_c_interface} {
    %c10 = arith.constant 10 : index
    %c5 = arith.constant 5 : index
    %c3 = arith.constant 3 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2x3xf32>
    cf.br ^bb1(%c0 : index)
  ^bb1(%0: index):  // 2 preds: ^bb0, ^bb4
    %1 = arith.cmpi slt, %0, %c2 : index
    cf.cond_br %1, ^bb2(%c0 : index), ^bb5
  ^bb2(%2: index):  // 2 preds: ^bb1, ^bb3
    %3 = arith.cmpi slt, %2, %c3 : index
    cf.cond_br %3, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %4 = memref.load %arg1[%2, %0] : memref<3x2xf32>
    memref.store %4, %alloc[%0, %2] : memref<2x3xf32>
    %5 = arith.addi %2, %c1 : index
    cf.br ^bb2(%5 : index)
  ^bb4:  // pred: ^bb2
    %6 = arith.addi %0, %c1 : index
    cf.br ^bb1(%6 : index)
  ^bb5:  // pred: ^bb1
    %base_buffer, %offset, %sizes:2, %strides:2 = memref.extract_strided_metadata %arg0 : memref<5x2xf32> -> memref<f32>, index, index, index, index, index
    %reinterpret_cast = memref.reinterpret_cast %base_buffer to offset: [%c0], sizes: [1, 5, 2], strides: [%c10, %c2, %c1] : memref<f32> to memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
    %reinterpret_cast_0 = memref.reinterpret_cast %alloc to offset: [0], sizes: [1, 2, 3], strides: [6, 3, 1] : memref<2x3xf32> to memref<1x2x3xf32>
    %alloc_1 = memref.alloc() {alignment = 64 : i64} : memref<1x5x3xf32>
    cf.br ^bb6(%c0 : index)
  ^bb6(%7: index):  // 2 preds: ^bb5, ^bb11
    %8 = arith.cmpi slt, %7, %c1 : index
    cf.cond_br %8, ^bb7(%c0 : index), ^bb12(%c0 : index)
  ^bb7(%9: index):  // 2 preds: ^bb6, ^bb10
    %10 = arith.cmpi slt, %9, %c5 : index
    cf.cond_br %10, ^bb8(%c0 : index), ^bb11
  ^bb8(%11: index):  // 2 preds: ^bb7, ^bb9
    %12 = arith.cmpi slt, %11, %c3 : index
    cf.cond_br %12, ^bb9, ^bb10
  ^bb9:  // pred: ^bb8
    memref.store %cst, %alloc_1[%7, %9, %11] : memref<1x5x3xf32>
    %13 = arith.addi %11, %c1 : index
    cf.br ^bb8(%13 : index)
  ^bb10:  // pred: ^bb8
    %14 = arith.addi %9, %c1 : index
    cf.br ^bb7(%14 : index)
  ^bb11:  // pred: ^bb7
    %15 = arith.addi %7, %c1 : index
    cf.br ^bb6(%15 : index)
  ^bb12(%16: index):  // 2 preds: ^bb6, ^bb19
    %17 = arith.cmpi slt, %16, %c1 : index
    cf.cond_br %17, ^bb13(%c0 : index), ^bb20
  ^bb13(%18: index):  // 2 preds: ^bb12, ^bb18
    %19 = arith.cmpi slt, %18, %c5 : index
    cf.cond_br %19, ^bb14(%c0 : index), ^bb19
  ^bb14(%20: index):  // 2 preds: ^bb13, ^bb17
    %21 = arith.cmpi slt, %20, %c3 : index
    cf.cond_br %21, ^bb15(%c0 : index), ^bb18
  ^bb15(%22: index):  // 2 preds: ^bb14, ^bb16
    %23 = arith.cmpi slt, %22, %c2 : index
    cf.cond_br %23, ^bb16, ^bb17
  ^bb16:  // pred: ^bb15
    %24 = memref.load %reinterpret_cast[%16, %18, %22] : memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
    %25 = memref.load %reinterpret_cast_0[%16, %22, %20] : memref<1x2x3xf32>
    %26 = memref.load %alloc_1[%16, %18, %20] : memref<1x5x3xf32>
    %27 = arith.mulf %24, %25 : f32
    %28 = arith.addf %26, %27 : f32
    memref.store %28, %alloc_1[%16, %18, %20] : memref<1x5x3xf32>
    %29 = arith.addi %22, %c1 : index
    cf.br ^bb15(%29 : index)
  ^bb17:  // pred: ^bb15
    %30 = arith.addi %20, %c1 : index
    cf.br ^bb14(%30 : index)
  ^bb18:  // pred: ^bb14
    %31 = arith.addi %18, %c1 : index
    cf.br ^bb13(%31 : index)
  ^bb19:  // pred: ^bb13
    %32 = arith.addi %16, %c1 : index
    cf.br ^bb12(%32 : index)
  ^bb20:  // pred: ^bb12
    %reinterpret_cast_2 = memref.reinterpret_cast %alloc_1 to offset: [0], sizes: [5, 3], strides: [3, 1] : memref<1x5x3xf32> to memref<5x3xf32>
    return %reinterpret_cast_2 : memref<5x3xf32>
  }
}


// -----// IR Dump After ConvertMathToLLVMPass (convert-math-to-llvm) //----- //
module {
  memref.global "private" constant @__constant_2xi32 : memref<2xi32> = dense<[1, 0]> {alignment = 64 : i64}
  func.func @test_linear(%arg0: memref<5x2xf32>, %arg1: memref<3x2xf32>) -> memref<5x3xf32> attributes {llvm.emit_c_interface} {
    %c10 = arith.constant 10 : index
    %c5 = arith.constant 5 : index
    %c3 = arith.constant 3 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2x3xf32>
    cf.br ^bb1(%c0 : index)
  ^bb1(%0: index):  // 2 preds: ^bb0, ^bb4
    %1 = arith.cmpi slt, %0, %c2 : index
    cf.cond_br %1, ^bb2(%c0 : index), ^bb5
  ^bb2(%2: index):  // 2 preds: ^bb1, ^bb3
    %3 = arith.cmpi slt, %2, %c3 : index
    cf.cond_br %3, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %4 = memref.load %arg1[%2, %0] : memref<3x2xf32>
    memref.store %4, %alloc[%0, %2] : memref<2x3xf32>
    %5 = arith.addi %2, %c1 : index
    cf.br ^bb2(%5 : index)
  ^bb4:  // pred: ^bb2
    %6 = arith.addi %0, %c1 : index
    cf.br ^bb1(%6 : index)
  ^bb5:  // pred: ^bb1
    %base_buffer, %offset, %sizes:2, %strides:2 = memref.extract_strided_metadata %arg0 : memref<5x2xf32> -> memref<f32>, index, index, index, index, index
    %reinterpret_cast = memref.reinterpret_cast %base_buffer to offset: [%c0], sizes: [1, 5, 2], strides: [%c10, %c2, %c1] : memref<f32> to memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
    %reinterpret_cast_0 = memref.reinterpret_cast %alloc to offset: [0], sizes: [1, 2, 3], strides: [6, 3, 1] : memref<2x3xf32> to memref<1x2x3xf32>
    %alloc_1 = memref.alloc() {alignment = 64 : i64} : memref<1x5x3xf32>
    cf.br ^bb6(%c0 : index)
  ^bb6(%7: index):  // 2 preds: ^bb5, ^bb11
    %8 = arith.cmpi slt, %7, %c1 : index
    cf.cond_br %8, ^bb7(%c0 : index), ^bb12(%c0 : index)
  ^bb7(%9: index):  // 2 preds: ^bb6, ^bb10
    %10 = arith.cmpi slt, %9, %c5 : index
    cf.cond_br %10, ^bb8(%c0 : index), ^bb11
  ^bb8(%11: index):  // 2 preds: ^bb7, ^bb9
    %12 = arith.cmpi slt, %11, %c3 : index
    cf.cond_br %12, ^bb9, ^bb10
  ^bb9:  // pred: ^bb8
    memref.store %cst, %alloc_1[%7, %9, %11] : memref<1x5x3xf32>
    %13 = arith.addi %11, %c1 : index
    cf.br ^bb8(%13 : index)
  ^bb10:  // pred: ^bb8
    %14 = arith.addi %9, %c1 : index
    cf.br ^bb7(%14 : index)
  ^bb11:  // pred: ^bb7
    %15 = arith.addi %7, %c1 : index
    cf.br ^bb6(%15 : index)
  ^bb12(%16: index):  // 2 preds: ^bb6, ^bb19
    %17 = arith.cmpi slt, %16, %c1 : index
    cf.cond_br %17, ^bb13(%c0 : index), ^bb20
  ^bb13(%18: index):  // 2 preds: ^bb12, ^bb18
    %19 = arith.cmpi slt, %18, %c5 : index
    cf.cond_br %19, ^bb14(%c0 : index), ^bb19
  ^bb14(%20: index):  // 2 preds: ^bb13, ^bb17
    %21 = arith.cmpi slt, %20, %c3 : index
    cf.cond_br %21, ^bb15(%c0 : index), ^bb18
  ^bb15(%22: index):  // 2 preds: ^bb14, ^bb16
    %23 = arith.cmpi slt, %22, %c2 : index
    cf.cond_br %23, ^bb16, ^bb17
  ^bb16:  // pred: ^bb15
    %24 = memref.load %reinterpret_cast[%16, %18, %22] : memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
    %25 = memref.load %reinterpret_cast_0[%16, %22, %20] : memref<1x2x3xf32>
    %26 = memref.load %alloc_1[%16, %18, %20] : memref<1x5x3xf32>
    %27 = arith.mulf %24, %25 : f32
    %28 = arith.addf %26, %27 : f32
    memref.store %28, %alloc_1[%16, %18, %20] : memref<1x5x3xf32>
    %29 = arith.addi %22, %c1 : index
    cf.br ^bb15(%29 : index)
  ^bb17:  // pred: ^bb15
    %30 = arith.addi %20, %c1 : index
    cf.br ^bb14(%30 : index)
  ^bb18:  // pred: ^bb14
    %31 = arith.addi %18, %c1 : index
    cf.br ^bb13(%31 : index)
  ^bb19:  // pred: ^bb13
    %32 = arith.addi %16, %c1 : index
    cf.br ^bb12(%32 : index)
  ^bb20:  // pred: ^bb12
    %reinterpret_cast_2 = memref.reinterpret_cast %alloc_1 to offset: [0], sizes: [5, 3], strides: [3, 1] : memref<1x5x3xf32> to memref<5x3xf32>
    return %reinterpret_cast_2 : memref<5x3xf32>
  }
}


// -----// IR Dump After ConvertMathToLibm (convert-math-to-libm) //----- //
module {
  memref.global "private" constant @__constant_2xi32 : memref<2xi32> = dense<[1, 0]> {alignment = 64 : i64}
  func.func @test_linear(%arg0: memref<5x2xf32>, %arg1: memref<3x2xf32>) -> memref<5x3xf32> attributes {llvm.emit_c_interface} {
    %c10 = arith.constant 10 : index
    %c5 = arith.constant 5 : index
    %c3 = arith.constant 3 : index
    %c1 = arith.constant 1 : index
    %c2 = arith.constant 2 : index
    %c0 = arith.constant 0 : index
    %cst = arith.constant 0.000000e+00 : f32
    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2x3xf32>
    cf.br ^bb1(%c0 : index)
  ^bb1(%0: index):  // 2 preds: ^bb0, ^bb4
    %1 = arith.cmpi slt, %0, %c2 : index
    cf.cond_br %1, ^bb2(%c0 : index), ^bb5
  ^bb2(%2: index):  // 2 preds: ^bb1, ^bb3
    %3 = arith.cmpi slt, %2, %c3 : index
    cf.cond_br %3, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %4 = memref.load %arg1[%2, %0] : memref<3x2xf32>
    memref.store %4, %alloc[%0, %2] : memref<2x3xf32>
    %5 = arith.addi %2, %c1 : index
    cf.br ^bb2(%5 : index)
  ^bb4:  // pred: ^bb2
    %6 = arith.addi %0, %c1 : index
    cf.br ^bb1(%6 : index)
  ^bb5:  // pred: ^bb1
    %base_buffer, %offset, %sizes:2, %strides:2 = memref.extract_strided_metadata %arg0 : memref<5x2xf32> -> memref<f32>, index, index, index, index, index
    %reinterpret_cast = memref.reinterpret_cast %base_buffer to offset: [%c0], sizes: [1, 5, 2], strides: [%c10, %c2, %c1] : memref<f32> to memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
    %reinterpret_cast_0 = memref.reinterpret_cast %alloc to offset: [0], sizes: [1, 2, 3], strides: [6, 3, 1] : memref<2x3xf32> to memref<1x2x3xf32>
    %alloc_1 = memref.alloc() {alignment = 64 : i64} : memref<1x5x3xf32>
    cf.br ^bb6(%c0 : index)
  ^bb6(%7: index):  // 2 preds: ^bb5, ^bb11
    %8 = arith.cmpi slt, %7, %c1 : index
    cf.cond_br %8, ^bb7(%c0 : index), ^bb12(%c0 : index)
  ^bb7(%9: index):  // 2 preds: ^bb6, ^bb10
    %10 = arith.cmpi slt, %9, %c5 : index
    cf.cond_br %10, ^bb8(%c0 : index), ^bb11
  ^bb8(%11: index):  // 2 preds: ^bb7, ^bb9
    %12 = arith.cmpi slt, %11, %c3 : index
    cf.cond_br %12, ^bb9, ^bb10
  ^bb9:  // pred: ^bb8
    memref.store %cst, %alloc_1[%7, %9, %11] : memref<1x5x3xf32>
    %13 = arith.addi %11, %c1 : index
    cf.br ^bb8(%13 : index)
  ^bb10:  // pred: ^bb8
    %14 = arith.addi %9, %c1 : index
    cf.br ^bb7(%14 : index)
  ^bb11:  // pred: ^bb7
    %15 = arith.addi %7, %c1 : index
    cf.br ^bb6(%15 : index)
  ^bb12(%16: index):  // 2 preds: ^bb6, ^bb19
    %17 = arith.cmpi slt, %16, %c1 : index
    cf.cond_br %17, ^bb13(%c0 : index), ^bb20
  ^bb13(%18: index):  // 2 preds: ^bb12, ^bb18
    %19 = arith.cmpi slt, %18, %c5 : index
    cf.cond_br %19, ^bb14(%c0 : index), ^bb19
  ^bb14(%20: index):  // 2 preds: ^bb13, ^bb17
    %21 = arith.cmpi slt, %20, %c3 : index
    cf.cond_br %21, ^bb15(%c0 : index), ^bb18
  ^bb15(%22: index):  // 2 preds: ^bb14, ^bb16
    %23 = arith.cmpi slt, %22, %c2 : index
    cf.cond_br %23, ^bb16, ^bb17
  ^bb16:  // pred: ^bb15
    %24 = memref.load %reinterpret_cast[%16, %18, %22] : memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
    %25 = memref.load %reinterpret_cast_0[%16, %22, %20] : memref<1x2x3xf32>
    %26 = memref.load %alloc_1[%16, %18, %20] : memref<1x5x3xf32>
    %27 = arith.mulf %24, %25 : f32
    %28 = arith.addf %26, %27 : f32
    memref.store %28, %alloc_1[%16, %18, %20] : memref<1x5x3xf32>
    %29 = arith.addi %22, %c1 : index
    cf.br ^bb15(%29 : index)
  ^bb17:  // pred: ^bb15
    %30 = arith.addi %20, %c1 : index
    cf.br ^bb14(%30 : index)
  ^bb18:  // pred: ^bb14
    %31 = arith.addi %18, %c1 : index
    cf.br ^bb13(%31 : index)
  ^bb19:  // pred: ^bb13
    %32 = arith.addi %16, %c1 : index
    cf.br ^bb12(%32 : index)
  ^bb20:  // pred: ^bb12
    %reinterpret_cast_2 = memref.reinterpret_cast %alloc_1 to offset: [0], sizes: [5, 3], strides: [3, 1] : memref<1x5x3xf32> to memref<5x3xf32>
    return %reinterpret_cast_2 : memref<5x3xf32>
  }
}


// -----// IR Dump After ArithToLLVMConversionPass (convert-arith-to-llvm) //----- //
module {
  memref.global "private" constant @__constant_2xi32 : memref<2xi32> = dense<[1, 0]> {alignment = 64 : i64}
  func.func @test_linear(%arg0: memref<5x2xf32>, %arg1: memref<3x2xf32>) -> memref<5x3xf32> attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.constant(10 : index) : i64
    %1 = builtin.unrealized_conversion_cast %0 : i64 to index
    %2 = llvm.mlir.constant(5 : index) : i64
    %3 = llvm.mlir.constant(3 : index) : i64
    %4 = llvm.mlir.constant(1 : index) : i64
    %5 = builtin.unrealized_conversion_cast %4 : i64 to index
    %6 = llvm.mlir.constant(2 : index) : i64
    %7 = builtin.unrealized_conversion_cast %6 : i64 to index
    %8 = llvm.mlir.constant(0 : index) : i64
    %9 = builtin.unrealized_conversion_cast %8 : i64 to index
    %10 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2x3xf32>
    cf.br ^bb1(%9 : index)
  ^bb1(%11: index):  // 2 preds: ^bb0, ^bb4
    %12 = builtin.unrealized_conversion_cast %11 : index to i64
    %13 = llvm.icmp "slt" %12, %6 : i64
    cf.cond_br %13, ^bb2(%9 : index), ^bb5
  ^bb2(%14: index):  // 2 preds: ^bb1, ^bb3
    %15 = builtin.unrealized_conversion_cast %14 : index to i64
    %16 = llvm.icmp "slt" %15, %3 : i64
    cf.cond_br %16, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %17 = memref.load %arg1[%14, %11] : memref<3x2xf32>
    memref.store %17, %alloc[%11, %14] : memref<2x3xf32>
    %18 = llvm.add %15, %4 : i64
    %19 = builtin.unrealized_conversion_cast %18 : i64 to index
    cf.br ^bb2(%19 : index)
  ^bb4:  // pred: ^bb2
    %20 = llvm.add %12, %4 : i64
    %21 = builtin.unrealized_conversion_cast %20 : i64 to index
    cf.br ^bb1(%21 : index)
  ^bb5:  // pred: ^bb1
    %base_buffer, %offset, %sizes:2, %strides:2 = memref.extract_strided_metadata %arg0 : memref<5x2xf32> -> memref<f32>, index, index, index, index, index
    %reinterpret_cast = memref.reinterpret_cast %base_buffer to offset: [%9], sizes: [1, 5, 2], strides: [%1, %7, %5] : memref<f32> to memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
    %reinterpret_cast_0 = memref.reinterpret_cast %alloc to offset: [0], sizes: [1, 2, 3], strides: [6, 3, 1] : memref<2x3xf32> to memref<1x2x3xf32>
    %alloc_1 = memref.alloc() {alignment = 64 : i64} : memref<1x5x3xf32>
    cf.br ^bb6(%9 : index)
  ^bb6(%22: index):  // 2 preds: ^bb5, ^bb11
    %23 = builtin.unrealized_conversion_cast %22 : index to i64
    %24 = llvm.icmp "slt" %23, %4 : i64
    cf.cond_br %24, ^bb7(%9 : index), ^bb12(%9 : index)
  ^bb7(%25: index):  // 2 preds: ^bb6, ^bb10
    %26 = builtin.unrealized_conversion_cast %25 : index to i64
    %27 = llvm.icmp "slt" %26, %2 : i64
    cf.cond_br %27, ^bb8(%9 : index), ^bb11
  ^bb8(%28: index):  // 2 preds: ^bb7, ^bb9
    %29 = builtin.unrealized_conversion_cast %28 : index to i64
    %30 = llvm.icmp "slt" %29, %3 : i64
    cf.cond_br %30, ^bb9, ^bb10
  ^bb9:  // pred: ^bb8
    memref.store %10, %alloc_1[%22, %25, %28] : memref<1x5x3xf32>
    %31 = llvm.add %29, %4 : i64
    %32 = builtin.unrealized_conversion_cast %31 : i64 to index
    cf.br ^bb8(%32 : index)
  ^bb10:  // pred: ^bb8
    %33 = llvm.add %26, %4 : i64
    %34 = builtin.unrealized_conversion_cast %33 : i64 to index
    cf.br ^bb7(%34 : index)
  ^bb11:  // pred: ^bb7
    %35 = llvm.add %23, %4 : i64
    %36 = builtin.unrealized_conversion_cast %35 : i64 to index
    cf.br ^bb6(%36 : index)
  ^bb12(%37: index):  // 2 preds: ^bb6, ^bb19
    %38 = builtin.unrealized_conversion_cast %37 : index to i64
    %39 = llvm.icmp "slt" %38, %4 : i64
    cf.cond_br %39, ^bb13(%9 : index), ^bb20
  ^bb13(%40: index):  // 2 preds: ^bb12, ^bb18
    %41 = builtin.unrealized_conversion_cast %40 : index to i64
    %42 = llvm.icmp "slt" %41, %2 : i64
    cf.cond_br %42, ^bb14(%9 : index), ^bb19
  ^bb14(%43: index):  // 2 preds: ^bb13, ^bb17
    %44 = builtin.unrealized_conversion_cast %43 : index to i64
    %45 = llvm.icmp "slt" %44, %3 : i64
    cf.cond_br %45, ^bb15(%9 : index), ^bb18
  ^bb15(%46: index):  // 2 preds: ^bb14, ^bb16
    %47 = builtin.unrealized_conversion_cast %46 : index to i64
    %48 = llvm.icmp "slt" %47, %6 : i64
    cf.cond_br %48, ^bb16, ^bb17
  ^bb16:  // pred: ^bb15
    %49 = memref.load %reinterpret_cast[%37, %40, %46] : memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
    %50 = memref.load %reinterpret_cast_0[%37, %46, %43] : memref<1x2x3xf32>
    %51 = memref.load %alloc_1[%37, %40, %43] : memref<1x5x3xf32>
    %52 = llvm.fmul %49, %50  : f32
    %53 = llvm.fadd %51, %52  : f32
    memref.store %53, %alloc_1[%37, %40, %43] : memref<1x5x3xf32>
    %54 = llvm.add %47, %4 : i64
    %55 = builtin.unrealized_conversion_cast %54 : i64 to index
    cf.br ^bb15(%55 : index)
  ^bb17:  // pred: ^bb15
    %56 = llvm.add %44, %4 : i64
    %57 = builtin.unrealized_conversion_cast %56 : i64 to index
    cf.br ^bb14(%57 : index)
  ^bb18:  // pred: ^bb14
    %58 = llvm.add %41, %4 : i64
    %59 = builtin.unrealized_conversion_cast %58 : i64 to index
    cf.br ^bb13(%59 : index)
  ^bb19:  // pred: ^bb13
    %60 = llvm.add %38, %4 : i64
    %61 = builtin.unrealized_conversion_cast %60 : i64 to index
    cf.br ^bb12(%61 : index)
  ^bb20:  // pred: ^bb12
    %reinterpret_cast_2 = memref.reinterpret_cast %alloc_1 to offset: [0], sizes: [5, 3], strides: [3, 1] : memref<1x5x3xf32> to memref<5x3xf32>
    return %reinterpret_cast_2 : memref<5x3xf32>
  }
}


// -----// IR Dump After ConvertFuncToLLVMPass (convert-func-to-llvm) //----- //
module {
  memref.global "private" constant @__constant_2xi32 : memref<2xi32> = dense<[1, 0]> {alignment = 64 : i64}
  llvm.func @test_linear(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64) -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.insertvalue %arg7, %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.insertvalue %arg8, %1[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.insertvalue %arg9, %2[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.insertvalue %arg10, %3[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.insertvalue %arg12, %4[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.insertvalue %arg11, %5[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg13, %6[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = builtin.unrealized_conversion_cast %7 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<3x2xf32>
    %9 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %10 = llvm.insertvalue %arg0, %9[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg1, %10[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg2, %11[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.insertvalue %arg3, %12[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.insertvalue %arg5, %13[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg4, %14[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg6, %15[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = builtin.unrealized_conversion_cast %16 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<5x2xf32>
    %18 = llvm.mlir.constant(10 : index) : i64
    %19 = builtin.unrealized_conversion_cast %18 : i64 to index
    %20 = llvm.mlir.constant(5 : index) : i64
    %21 = llvm.mlir.constant(3 : index) : i64
    %22 = llvm.mlir.constant(1 : index) : i64
    %23 = builtin.unrealized_conversion_cast %22 : i64 to index
    %24 = llvm.mlir.constant(2 : index) : i64
    %25 = builtin.unrealized_conversion_cast %24 : i64 to index
    %26 = llvm.mlir.constant(0 : index) : i64
    %27 = builtin.unrealized_conversion_cast %26 : i64 to index
    %28 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2x3xf32>
    llvm.br ^bb1(%26 : i64)
  ^bb1(%29: i64):  // 2 preds: ^bb0, ^bb4
    %30 = builtin.unrealized_conversion_cast %29 : i64 to index
    %31 = builtin.unrealized_conversion_cast %30 : index to i64
    %32 = llvm.icmp "slt" %31, %24 : i64
    llvm.cond_br %32, ^bb2(%26 : i64), ^bb5
  ^bb2(%33: i64):  // 2 preds: ^bb1, ^bb3
    %34 = builtin.unrealized_conversion_cast %33 : i64 to index
    %35 = builtin.unrealized_conversion_cast %34 : index to i64
    %36 = llvm.icmp "slt" %35, %21 : i64
    llvm.cond_br %36, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %37 = memref.load %8[%34, %30] : memref<3x2xf32>
    memref.store %37, %alloc[%30, %34] : memref<2x3xf32>
    %38 = llvm.add %35, %22 : i64
    %39 = builtin.unrealized_conversion_cast %38 : i64 to index
    llvm.br ^bb2(%38 : i64)
  ^bb4:  // pred: ^bb2
    %40 = llvm.add %31, %22 : i64
    %41 = builtin.unrealized_conversion_cast %40 : i64 to index
    llvm.br ^bb1(%40 : i64)
  ^bb5:  // pred: ^bb1
    %base_buffer, %offset, %sizes:2, %strides:2 = memref.extract_strided_metadata %17 : memref<5x2xf32> -> memref<f32>, index, index, index, index, index
    %reinterpret_cast = memref.reinterpret_cast %base_buffer to offset: [%27], sizes: [1, 5, 2], strides: [%19, %25, %23] : memref<f32> to memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
    %reinterpret_cast_0 = memref.reinterpret_cast %alloc to offset: [0], sizes: [1, 2, 3], strides: [6, 3, 1] : memref<2x3xf32> to memref<1x2x3xf32>
    %alloc_1 = memref.alloc() {alignment = 64 : i64} : memref<1x5x3xf32>
    llvm.br ^bb6(%26 : i64)
  ^bb6(%42: i64):  // 2 preds: ^bb5, ^bb11
    %43 = builtin.unrealized_conversion_cast %42 : i64 to index
    %44 = builtin.unrealized_conversion_cast %43 : index to i64
    %45 = llvm.icmp "slt" %44, %22 : i64
    llvm.cond_br %45, ^bb7(%26 : i64), ^bb12(%26 : i64)
  ^bb7(%46: i64):  // 2 preds: ^bb6, ^bb10
    %47 = builtin.unrealized_conversion_cast %46 : i64 to index
    %48 = builtin.unrealized_conversion_cast %47 : index to i64
    %49 = llvm.icmp "slt" %48, %20 : i64
    llvm.cond_br %49, ^bb8(%26 : i64), ^bb11
  ^bb8(%50: i64):  // 2 preds: ^bb7, ^bb9
    %51 = builtin.unrealized_conversion_cast %50 : i64 to index
    %52 = builtin.unrealized_conversion_cast %51 : index to i64
    %53 = llvm.icmp "slt" %52, %21 : i64
    llvm.cond_br %53, ^bb9, ^bb10
  ^bb9:  // pred: ^bb8
    memref.store %28, %alloc_1[%43, %47, %51] : memref<1x5x3xf32>
    %54 = llvm.add %52, %22 : i64
    %55 = builtin.unrealized_conversion_cast %54 : i64 to index
    llvm.br ^bb8(%54 : i64)
  ^bb10:  // pred: ^bb8
    %56 = llvm.add %48, %22 : i64
    %57 = builtin.unrealized_conversion_cast %56 : i64 to index
    llvm.br ^bb7(%56 : i64)
  ^bb11:  // pred: ^bb7
    %58 = llvm.add %44, %22 : i64
    %59 = builtin.unrealized_conversion_cast %58 : i64 to index
    llvm.br ^bb6(%58 : i64)
  ^bb12(%60: i64):  // 2 preds: ^bb6, ^bb19
    %61 = builtin.unrealized_conversion_cast %60 : i64 to index
    %62 = builtin.unrealized_conversion_cast %61 : index to i64
    %63 = llvm.icmp "slt" %62, %22 : i64
    llvm.cond_br %63, ^bb13(%26 : i64), ^bb20
  ^bb13(%64: i64):  // 2 preds: ^bb12, ^bb18
    %65 = builtin.unrealized_conversion_cast %64 : i64 to index
    %66 = builtin.unrealized_conversion_cast %65 : index to i64
    %67 = llvm.icmp "slt" %66, %20 : i64
    llvm.cond_br %67, ^bb14(%26 : i64), ^bb19
  ^bb14(%68: i64):  // 2 preds: ^bb13, ^bb17
    %69 = builtin.unrealized_conversion_cast %68 : i64 to index
    %70 = builtin.unrealized_conversion_cast %69 : index to i64
    %71 = llvm.icmp "slt" %70, %21 : i64
    llvm.cond_br %71, ^bb15(%26 : i64), ^bb18
  ^bb15(%72: i64):  // 2 preds: ^bb14, ^bb16
    %73 = builtin.unrealized_conversion_cast %72 : i64 to index
    %74 = builtin.unrealized_conversion_cast %73 : index to i64
    %75 = llvm.icmp "slt" %74, %24 : i64
    llvm.cond_br %75, ^bb16, ^bb17
  ^bb16:  // pred: ^bb15
    %76 = memref.load %reinterpret_cast[%61, %65, %73] : memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
    %77 = memref.load %reinterpret_cast_0[%61, %73, %69] : memref<1x2x3xf32>
    %78 = memref.load %alloc_1[%61, %65, %69] : memref<1x5x3xf32>
    %79 = llvm.fmul %76, %77  : f32
    %80 = llvm.fadd %78, %79  : f32
    memref.store %80, %alloc_1[%61, %65, %69] : memref<1x5x3xf32>
    %81 = llvm.add %74, %22 : i64
    %82 = builtin.unrealized_conversion_cast %81 : i64 to index
    llvm.br ^bb15(%81 : i64)
  ^bb17:  // pred: ^bb15
    %83 = llvm.add %70, %22 : i64
    %84 = builtin.unrealized_conversion_cast %83 : i64 to index
    llvm.br ^bb14(%83 : i64)
  ^bb18:  // pred: ^bb14
    %85 = llvm.add %66, %22 : i64
    %86 = builtin.unrealized_conversion_cast %85 : i64 to index
    llvm.br ^bb13(%85 : i64)
  ^bb19:  // pred: ^bb13
    %87 = llvm.add %62, %22 : i64
    %88 = builtin.unrealized_conversion_cast %87 : i64 to index
    llvm.br ^bb12(%87 : i64)
  ^bb20:  // pred: ^bb12
    %reinterpret_cast_2 = memref.reinterpret_cast %alloc_1 to offset: [0], sizes: [5, 3], strides: [3, 1] : memref<1x5x3xf32> to memref<5x3xf32>
    %89 = builtin.unrealized_conversion_cast %reinterpret_cast_2 : memref<5x3xf32> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    llvm.return %89 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
  }
  llvm.func @_mlir_ciface_test_linear(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.call @test_linear(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    llvm.store %16, %arg0 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>, !llvm.ptr
    llvm.return
  }
}


// -----// IR Dump After ConvertControlFlowToLLVMPass (convert-cf-to-llvm) //----- //
module {
  memref.global "private" constant @__constant_2xi32 : memref<2xi32> = dense<[1, 0]> {alignment = 64 : i64}
  llvm.func @test_linear(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64) -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.insertvalue %arg7, %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.insertvalue %arg8, %1[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.insertvalue %arg9, %2[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.insertvalue %arg10, %3[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.insertvalue %arg12, %4[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.insertvalue %arg11, %5[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg13, %6[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = builtin.unrealized_conversion_cast %7 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<3x2xf32>
    %9 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %10 = llvm.insertvalue %arg0, %9[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg1, %10[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg2, %11[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.insertvalue %arg3, %12[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.insertvalue %arg5, %13[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg4, %14[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg6, %15[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = builtin.unrealized_conversion_cast %16 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<5x2xf32>
    %18 = llvm.mlir.constant(10 : index) : i64
    %19 = builtin.unrealized_conversion_cast %18 : i64 to index
    %20 = llvm.mlir.constant(5 : index) : i64
    %21 = llvm.mlir.constant(3 : index) : i64
    %22 = llvm.mlir.constant(1 : index) : i64
    %23 = builtin.unrealized_conversion_cast %22 : i64 to index
    %24 = llvm.mlir.constant(2 : index) : i64
    %25 = builtin.unrealized_conversion_cast %24 : i64 to index
    %26 = llvm.mlir.constant(0 : index) : i64
    %27 = builtin.unrealized_conversion_cast %26 : i64 to index
    %28 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %alloc = memref.alloc() {alignment = 64 : i64} : memref<2x3xf32>
    llvm.br ^bb1(%26 : i64)
  ^bb1(%29: i64):  // 2 preds: ^bb0, ^bb4
    %30 = builtin.unrealized_conversion_cast %29 : i64 to index
    %31 = builtin.unrealized_conversion_cast %30 : index to i64
    %32 = llvm.icmp "slt" %31, %24 : i64
    llvm.cond_br %32, ^bb2(%26 : i64), ^bb5
  ^bb2(%33: i64):  // 2 preds: ^bb1, ^bb3
    %34 = builtin.unrealized_conversion_cast %33 : i64 to index
    %35 = builtin.unrealized_conversion_cast %34 : index to i64
    %36 = llvm.icmp "slt" %35, %21 : i64
    llvm.cond_br %36, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %37 = memref.load %8[%34, %30] : memref<3x2xf32>
    memref.store %37, %alloc[%30, %34] : memref<2x3xf32>
    %38 = llvm.add %35, %22 : i64
    %39 = builtin.unrealized_conversion_cast %38 : i64 to index
    llvm.br ^bb2(%38 : i64)
  ^bb4:  // pred: ^bb2
    %40 = llvm.add %31, %22 : i64
    %41 = builtin.unrealized_conversion_cast %40 : i64 to index
    llvm.br ^bb1(%40 : i64)
  ^bb5:  // pred: ^bb1
    %base_buffer, %offset, %sizes:2, %strides:2 = memref.extract_strided_metadata %17 : memref<5x2xf32> -> memref<f32>, index, index, index, index, index
    %reinterpret_cast = memref.reinterpret_cast %base_buffer to offset: [%27], sizes: [1, 5, 2], strides: [%19, %25, %23] : memref<f32> to memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
    %reinterpret_cast_0 = memref.reinterpret_cast %alloc to offset: [0], sizes: [1, 2, 3], strides: [6, 3, 1] : memref<2x3xf32> to memref<1x2x3xf32>
    %alloc_1 = memref.alloc() {alignment = 64 : i64} : memref<1x5x3xf32>
    llvm.br ^bb6(%26 : i64)
  ^bb6(%42: i64):  // 2 preds: ^bb5, ^bb11
    %43 = builtin.unrealized_conversion_cast %42 : i64 to index
    %44 = builtin.unrealized_conversion_cast %43 : index to i64
    %45 = llvm.icmp "slt" %44, %22 : i64
    llvm.cond_br %45, ^bb7(%26 : i64), ^bb12(%26 : i64)
  ^bb7(%46: i64):  // 2 preds: ^bb6, ^bb10
    %47 = builtin.unrealized_conversion_cast %46 : i64 to index
    %48 = builtin.unrealized_conversion_cast %47 : index to i64
    %49 = llvm.icmp "slt" %48, %20 : i64
    llvm.cond_br %49, ^bb8(%26 : i64), ^bb11
  ^bb8(%50: i64):  // 2 preds: ^bb7, ^bb9
    %51 = builtin.unrealized_conversion_cast %50 : i64 to index
    %52 = builtin.unrealized_conversion_cast %51 : index to i64
    %53 = llvm.icmp "slt" %52, %21 : i64
    llvm.cond_br %53, ^bb9, ^bb10
  ^bb9:  // pred: ^bb8
    memref.store %28, %alloc_1[%43, %47, %51] : memref<1x5x3xf32>
    %54 = llvm.add %52, %22 : i64
    %55 = builtin.unrealized_conversion_cast %54 : i64 to index
    llvm.br ^bb8(%54 : i64)
  ^bb10:  // pred: ^bb8
    %56 = llvm.add %48, %22 : i64
    %57 = builtin.unrealized_conversion_cast %56 : i64 to index
    llvm.br ^bb7(%56 : i64)
  ^bb11:  // pred: ^bb7
    %58 = llvm.add %44, %22 : i64
    %59 = builtin.unrealized_conversion_cast %58 : i64 to index
    llvm.br ^bb6(%58 : i64)
  ^bb12(%60: i64):  // 2 preds: ^bb6, ^bb19
    %61 = builtin.unrealized_conversion_cast %60 : i64 to index
    %62 = builtin.unrealized_conversion_cast %61 : index to i64
    %63 = llvm.icmp "slt" %62, %22 : i64
    llvm.cond_br %63, ^bb13(%26 : i64), ^bb20
  ^bb13(%64: i64):  // 2 preds: ^bb12, ^bb18
    %65 = builtin.unrealized_conversion_cast %64 : i64 to index
    %66 = builtin.unrealized_conversion_cast %65 : index to i64
    %67 = llvm.icmp "slt" %66, %20 : i64
    llvm.cond_br %67, ^bb14(%26 : i64), ^bb19
  ^bb14(%68: i64):  // 2 preds: ^bb13, ^bb17
    %69 = builtin.unrealized_conversion_cast %68 : i64 to index
    %70 = builtin.unrealized_conversion_cast %69 : index to i64
    %71 = llvm.icmp "slt" %70, %21 : i64
    llvm.cond_br %71, ^bb15(%26 : i64), ^bb18
  ^bb15(%72: i64):  // 2 preds: ^bb14, ^bb16
    %73 = builtin.unrealized_conversion_cast %72 : i64 to index
    %74 = builtin.unrealized_conversion_cast %73 : index to i64
    %75 = llvm.icmp "slt" %74, %24 : i64
    llvm.cond_br %75, ^bb16, ^bb17
  ^bb16:  // pred: ^bb15
    %76 = memref.load %reinterpret_cast[%61, %65, %73] : memref<1x5x2xf32, strided<[?, ?, ?], offset: ?>>
    %77 = memref.load %reinterpret_cast_0[%61, %73, %69] : memref<1x2x3xf32>
    %78 = memref.load %alloc_1[%61, %65, %69] : memref<1x5x3xf32>
    %79 = llvm.fmul %76, %77  : f32
    %80 = llvm.fadd %78, %79  : f32
    memref.store %80, %alloc_1[%61, %65, %69] : memref<1x5x3xf32>
    %81 = llvm.add %74, %22 : i64
    %82 = builtin.unrealized_conversion_cast %81 : i64 to index
    llvm.br ^bb15(%81 : i64)
  ^bb17:  // pred: ^bb15
    %83 = llvm.add %70, %22 : i64
    %84 = builtin.unrealized_conversion_cast %83 : i64 to index
    llvm.br ^bb14(%83 : i64)
  ^bb18:  // pred: ^bb14
    %85 = llvm.add %66, %22 : i64
    %86 = builtin.unrealized_conversion_cast %85 : i64 to index
    llvm.br ^bb13(%85 : i64)
  ^bb19:  // pred: ^bb13
    %87 = llvm.add %62, %22 : i64
    %88 = builtin.unrealized_conversion_cast %87 : i64 to index
    llvm.br ^bb12(%87 : i64)
  ^bb20:  // pred: ^bb12
    %reinterpret_cast_2 = memref.reinterpret_cast %alloc_1 to offset: [0], sizes: [5, 3], strides: [3, 1] : memref<1x5x3xf32> to memref<5x3xf32>
    %89 = builtin.unrealized_conversion_cast %reinterpret_cast_2 : memref<5x3xf32> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    llvm.return %89 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
  }
  llvm.func @_mlir_ciface_test_linear(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.call @test_linear(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    llvm.store %16, %arg0 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>, !llvm.ptr
    llvm.return
  }
}


// -----// IR Dump After FinalizeMemRefToLLVMConversionPass (finalize-memref-to-llvm) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  llvm.mlir.global private constant @__constant_2xi32(dense<[1, 0]> : tensor<2xi32>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<2 x i32>
  llvm.func @test_linear(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64) -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.insertvalue %arg7, %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.insertvalue %arg8, %1[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.insertvalue %arg9, %2[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.insertvalue %arg10, %3[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.insertvalue %arg12, %4[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.insertvalue %arg11, %5[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg13, %6[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = builtin.unrealized_conversion_cast %7 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<3x2xf32>
    %9 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %10 = llvm.insertvalue %arg0, %9[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg1, %10[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg2, %11[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.insertvalue %arg3, %12[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.insertvalue %arg5, %13[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg4, %14[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.insertvalue %arg6, %15[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %17 = builtin.unrealized_conversion_cast %16 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<5x2xf32>
    %18 = llvm.mlir.constant(10 : index) : i64
    %19 = builtin.unrealized_conversion_cast %18 : i64 to index
    %20 = llvm.mlir.constant(5 : index) : i64
    %21 = llvm.mlir.constant(3 : index) : i64
    %22 = llvm.mlir.constant(1 : index) : i64
    %23 = builtin.unrealized_conversion_cast %22 : i64 to index
    %24 = llvm.mlir.constant(2 : index) : i64
    %25 = builtin.unrealized_conversion_cast %24 : i64 to index
    %26 = llvm.mlir.constant(0 : index) : i64
    %27 = builtin.unrealized_conversion_cast %26 : i64 to index
    %28 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %29 = llvm.mlir.constant(2 : index) : i64
    %30 = llvm.mlir.constant(3 : index) : i64
    %31 = llvm.mlir.constant(1 : index) : i64
    %32 = llvm.mlir.constant(6 : index) : i64
    %33 = llvm.mlir.zero : !llvm.ptr
    %34 = llvm.getelementptr %33[%32] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %35 = llvm.ptrtoint %34 : !llvm.ptr to i64
    %36 = llvm.mlir.constant(64 : index) : i64
    %37 = llvm.add %35, %36 : i64
    %38 = llvm.call @malloc(%37) : (i64) -> !llvm.ptr
    %39 = llvm.ptrtoint %38 : !llvm.ptr to i64
    %40 = llvm.mlir.constant(1 : index) : i64
    %41 = llvm.sub %36, %40 : i64
    %42 = llvm.add %39, %41 : i64
    %43 = llvm.urem %42, %36  : i64
    %44 = llvm.sub %42, %43 : i64
    %45 = llvm.inttoptr %44 : i64 to !llvm.ptr
    %46 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %47 = llvm.insertvalue %38, %46[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %48 = llvm.insertvalue %45, %47[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %49 = llvm.mlir.constant(0 : index) : i64
    %50 = llvm.insertvalue %49, %48[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %51 = llvm.insertvalue %29, %50[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %52 = llvm.insertvalue %30, %51[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %53 = llvm.insertvalue %30, %52[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %54 = llvm.insertvalue %31, %53[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.br ^bb1(%26 : i64)
  ^bb1(%55: i64):  // 2 preds: ^bb0, ^bb4
    %56 = builtin.unrealized_conversion_cast %55 : i64 to index
    %57 = builtin.unrealized_conversion_cast %56 : index to i64
    %58 = llvm.icmp "slt" %57, %24 : i64
    llvm.cond_br %58, ^bb2(%26 : i64), ^bb5
  ^bb2(%59: i64):  // 2 preds: ^bb1, ^bb3
    %60 = builtin.unrealized_conversion_cast %59 : i64 to index
    %61 = builtin.unrealized_conversion_cast %60 : index to i64
    %62 = llvm.icmp "slt" %61, %21 : i64
    llvm.cond_br %62, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %63 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %64 = llvm.mlir.constant(2 : index) : i64
    %65 = llvm.mul %59, %64 : i64
    %66 = llvm.add %65, %55 : i64
    %67 = llvm.getelementptr %63[%66] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %68 = llvm.load %67 : !llvm.ptr -> f32
    %69 = llvm.extractvalue %54[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %70 = llvm.mlir.constant(3 : index) : i64
    %71 = llvm.mul %55, %70 : i64
    %72 = llvm.add %71, %59 : i64
    %73 = llvm.getelementptr %69[%72] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %68, %73 : f32, !llvm.ptr
    %74 = llvm.add %61, %22 : i64
    %75 = builtin.unrealized_conversion_cast %74 : i64 to index
    llvm.br ^bb2(%74 : i64)
  ^bb4:  // pred: ^bb2
    %76 = llvm.add %57, %22 : i64
    %77 = builtin.unrealized_conversion_cast %76 : i64 to index
    llvm.br ^bb1(%76 : i64)
  ^bb5:  // pred: ^bb1
    %78 = llvm.extractvalue %16[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %79 = llvm.extractvalue %16[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %80 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64)>
    %81 = llvm.insertvalue %78, %80[0] : !llvm.struct<(ptr, ptr, i64)> 
    %82 = llvm.insertvalue %79, %81[1] : !llvm.struct<(ptr, ptr, i64)> 
    %83 = llvm.mlir.constant(0 : index) : i64
    %84 = llvm.insertvalue %83, %82[2] : !llvm.struct<(ptr, ptr, i64)> 
    %85 = llvm.extractvalue %16[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %86 = llvm.extractvalue %16[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %87 = llvm.extractvalue %16[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %88 = llvm.extractvalue %16[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %89 = llvm.extractvalue %16[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %90 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)>
    %91 = llvm.extractvalue %84[0] : !llvm.struct<(ptr, ptr, i64)> 
    %92 = llvm.extractvalue %84[1] : !llvm.struct<(ptr, ptr, i64)> 
    %93 = llvm.insertvalue %91, %90[0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %94 = llvm.insertvalue %92, %93[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %95 = llvm.insertvalue %26, %94[2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %96 = llvm.mlir.constant(1 : index) : i64
    %97 = llvm.insertvalue %96, %95[3, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %98 = llvm.insertvalue %18, %97[4, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %99 = llvm.mlir.constant(5 : index) : i64
    %100 = llvm.insertvalue %99, %98[3, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %101 = llvm.insertvalue %24, %100[4, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %102 = llvm.mlir.constant(2 : index) : i64
    %103 = llvm.insertvalue %102, %101[3, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %104 = llvm.insertvalue %22, %103[4, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %105 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)>
    %106 = llvm.extractvalue %54[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %107 = llvm.extractvalue %54[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %108 = llvm.insertvalue %106, %105[0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %109 = llvm.insertvalue %107, %108[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %110 = llvm.mlir.constant(0 : index) : i64
    %111 = llvm.insertvalue %110, %109[2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %112 = llvm.mlir.constant(1 : index) : i64
    %113 = llvm.insertvalue %112, %111[3, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %114 = llvm.mlir.constant(6 : index) : i64
    %115 = llvm.insertvalue %114, %113[4, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %116 = llvm.mlir.constant(2 : index) : i64
    %117 = llvm.insertvalue %116, %115[3, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %118 = llvm.mlir.constant(3 : index) : i64
    %119 = llvm.insertvalue %118, %117[4, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %120 = llvm.mlir.constant(3 : index) : i64
    %121 = llvm.insertvalue %120, %119[3, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %122 = llvm.mlir.constant(1 : index) : i64
    %123 = llvm.insertvalue %122, %121[4, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %124 = llvm.mlir.constant(1 : index) : i64
    %125 = llvm.mlir.constant(5 : index) : i64
    %126 = llvm.mlir.constant(3 : index) : i64
    %127 = llvm.mlir.constant(1 : index) : i64
    %128 = llvm.mlir.constant(15 : index) : i64
    %129 = llvm.mlir.constant(15 : index) : i64
    %130 = llvm.mlir.zero : !llvm.ptr
    %131 = llvm.getelementptr %130[%129] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %132 = llvm.ptrtoint %131 : !llvm.ptr to i64
    %133 = llvm.mlir.constant(64 : index) : i64
    %134 = llvm.add %132, %133 : i64
    %135 = llvm.call @malloc(%134) : (i64) -> !llvm.ptr
    %136 = llvm.ptrtoint %135 : !llvm.ptr to i64
    %137 = llvm.mlir.constant(1 : index) : i64
    %138 = llvm.sub %133, %137 : i64
    %139 = llvm.add %136, %138 : i64
    %140 = llvm.urem %139, %133  : i64
    %141 = llvm.sub %139, %140 : i64
    %142 = llvm.inttoptr %141 : i64 to !llvm.ptr
    %143 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)>
    %144 = llvm.insertvalue %135, %143[0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %145 = llvm.insertvalue %142, %144[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %146 = llvm.mlir.constant(0 : index) : i64
    %147 = llvm.insertvalue %146, %145[2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %148 = llvm.insertvalue %124, %147[3, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %149 = llvm.insertvalue %125, %148[3, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %150 = llvm.insertvalue %126, %149[3, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %151 = llvm.insertvalue %128, %150[4, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %152 = llvm.insertvalue %126, %151[4, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %153 = llvm.insertvalue %127, %152[4, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    llvm.br ^bb6(%26 : i64)
  ^bb6(%154: i64):  // 2 preds: ^bb5, ^bb11
    %155 = builtin.unrealized_conversion_cast %154 : i64 to index
    %156 = builtin.unrealized_conversion_cast %155 : index to i64
    %157 = llvm.icmp "slt" %156, %22 : i64
    llvm.cond_br %157, ^bb7(%26 : i64), ^bb12(%26 : i64)
  ^bb7(%158: i64):  // 2 preds: ^bb6, ^bb10
    %159 = builtin.unrealized_conversion_cast %158 : i64 to index
    %160 = builtin.unrealized_conversion_cast %159 : index to i64
    %161 = llvm.icmp "slt" %160, %20 : i64
    llvm.cond_br %161, ^bb8(%26 : i64), ^bb11
  ^bb8(%162: i64):  // 2 preds: ^bb7, ^bb9
    %163 = builtin.unrealized_conversion_cast %162 : i64 to index
    %164 = builtin.unrealized_conversion_cast %163 : index to i64
    %165 = llvm.icmp "slt" %164, %21 : i64
    llvm.cond_br %165, ^bb9, ^bb10
  ^bb9:  // pred: ^bb8
    %166 = llvm.extractvalue %153[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %167 = llvm.mlir.constant(15 : index) : i64
    %168 = llvm.mul %154, %167 : i64
    %169 = llvm.mlir.constant(3 : index) : i64
    %170 = llvm.mul %158, %169 : i64
    %171 = llvm.add %168, %170 : i64
    %172 = llvm.add %171, %162 : i64
    %173 = llvm.getelementptr %166[%172] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %28, %173 : f32, !llvm.ptr
    %174 = llvm.add %164, %22 : i64
    %175 = builtin.unrealized_conversion_cast %174 : i64 to index
    llvm.br ^bb8(%174 : i64)
  ^bb10:  // pred: ^bb8
    %176 = llvm.add %160, %22 : i64
    %177 = builtin.unrealized_conversion_cast %176 : i64 to index
    llvm.br ^bb7(%176 : i64)
  ^bb11:  // pred: ^bb7
    %178 = llvm.add %156, %22 : i64
    %179 = builtin.unrealized_conversion_cast %178 : i64 to index
    llvm.br ^bb6(%178 : i64)
  ^bb12(%180: i64):  // 2 preds: ^bb6, ^bb19
    %181 = builtin.unrealized_conversion_cast %180 : i64 to index
    %182 = builtin.unrealized_conversion_cast %181 : index to i64
    %183 = llvm.icmp "slt" %182, %22 : i64
    llvm.cond_br %183, ^bb13(%26 : i64), ^bb20
  ^bb13(%184: i64):  // 2 preds: ^bb12, ^bb18
    %185 = builtin.unrealized_conversion_cast %184 : i64 to index
    %186 = builtin.unrealized_conversion_cast %185 : index to i64
    %187 = llvm.icmp "slt" %186, %20 : i64
    llvm.cond_br %187, ^bb14(%26 : i64), ^bb19
  ^bb14(%188: i64):  // 2 preds: ^bb13, ^bb17
    %189 = builtin.unrealized_conversion_cast %188 : i64 to index
    %190 = builtin.unrealized_conversion_cast %189 : index to i64
    %191 = llvm.icmp "slt" %190, %21 : i64
    llvm.cond_br %191, ^bb15(%26 : i64), ^bb18
  ^bb15(%192: i64):  // 2 preds: ^bb14, ^bb16
    %193 = builtin.unrealized_conversion_cast %192 : i64 to index
    %194 = builtin.unrealized_conversion_cast %193 : index to i64
    %195 = llvm.icmp "slt" %194, %24 : i64
    llvm.cond_br %195, ^bb16, ^bb17
  ^bb16:  // pred: ^bb15
    %196 = llvm.extractvalue %104[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %197 = llvm.extractvalue %104[2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %198 = llvm.getelementptr %196[%197] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %199 = llvm.extractvalue %104[4, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %200 = llvm.mul %180, %199 : i64
    %201 = llvm.extractvalue %104[4, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %202 = llvm.mul %184, %201 : i64
    %203 = llvm.add %200, %202 : i64
    %204 = llvm.extractvalue %104[4, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %205 = llvm.mul %192, %204 : i64
    %206 = llvm.add %203, %205 : i64
    %207 = llvm.getelementptr %198[%206] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %208 = llvm.load %207 : !llvm.ptr -> f32
    %209 = llvm.extractvalue %123[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %210 = llvm.mlir.constant(6 : index) : i64
    %211 = llvm.mul %180, %210 : i64
    %212 = llvm.mlir.constant(3 : index) : i64
    %213 = llvm.mul %192, %212 : i64
    %214 = llvm.add %211, %213 : i64
    %215 = llvm.add %214, %188 : i64
    %216 = llvm.getelementptr %209[%215] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %217 = llvm.load %216 : !llvm.ptr -> f32
    %218 = llvm.extractvalue %153[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %219 = llvm.mlir.constant(15 : index) : i64
    %220 = llvm.mul %180, %219 : i64
    %221 = llvm.mlir.constant(3 : index) : i64
    %222 = llvm.mul %184, %221 : i64
    %223 = llvm.add %220, %222 : i64
    %224 = llvm.add %223, %188 : i64
    %225 = llvm.getelementptr %218[%224] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %226 = llvm.load %225 : !llvm.ptr -> f32
    %227 = llvm.fmul %208, %217  : f32
    %228 = llvm.fadd %226, %227  : f32
    %229 = llvm.extractvalue %153[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %230 = llvm.mlir.constant(15 : index) : i64
    %231 = llvm.mul %180, %230 : i64
    %232 = llvm.mlir.constant(3 : index) : i64
    %233 = llvm.mul %184, %232 : i64
    %234 = llvm.add %231, %233 : i64
    %235 = llvm.add %234, %188 : i64
    %236 = llvm.getelementptr %229[%235] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %228, %236 : f32, !llvm.ptr
    %237 = llvm.add %194, %22 : i64
    %238 = builtin.unrealized_conversion_cast %237 : i64 to index
    llvm.br ^bb15(%237 : i64)
  ^bb17:  // pred: ^bb15
    %239 = llvm.add %190, %22 : i64
    %240 = builtin.unrealized_conversion_cast %239 : i64 to index
    llvm.br ^bb14(%239 : i64)
  ^bb18:  // pred: ^bb14
    %241 = llvm.add %186, %22 : i64
    %242 = builtin.unrealized_conversion_cast %241 : i64 to index
    llvm.br ^bb13(%241 : i64)
  ^bb19:  // pred: ^bb13
    %243 = llvm.add %182, %22 : i64
    %244 = builtin.unrealized_conversion_cast %243 : i64 to index
    llvm.br ^bb12(%243 : i64)
  ^bb20:  // pred: ^bb12
    %245 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %246 = llvm.extractvalue %153[0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %247 = llvm.extractvalue %153[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %248 = llvm.insertvalue %246, %245[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %249 = llvm.insertvalue %247, %248[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %250 = llvm.mlir.constant(0 : index) : i64
    %251 = llvm.insertvalue %250, %249[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %252 = llvm.mlir.constant(5 : index) : i64
    %253 = llvm.insertvalue %252, %251[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %254 = llvm.mlir.constant(3 : index) : i64
    %255 = llvm.insertvalue %254, %253[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %256 = llvm.mlir.constant(3 : index) : i64
    %257 = llvm.insertvalue %256, %255[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %258 = llvm.mlir.constant(1 : index) : i64
    %259 = llvm.insertvalue %258, %257[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %260 = builtin.unrealized_conversion_cast %259 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> to memref<5x3xf32>
    %261 = builtin.unrealized_conversion_cast %260 : memref<5x3xf32> to !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    llvm.return %261 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
  }
  llvm.func @_mlir_ciface_test_linear(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.call @test_linear(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    llvm.store %16, %arg0 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>, !llvm.ptr
    llvm.return
  }
}


// -----// IR Dump After ReconcileUnrealizedCasts (reconcile-unrealized-casts) //----- //
module {
  llvm.func @malloc(i64) -> !llvm.ptr
  llvm.mlir.global private constant @__constant_2xi32(dense<[1, 0]> : tensor<2xi32>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<2 x i32>
  llvm.func @test_linear(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64) -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.insertvalue %arg7, %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.insertvalue %arg8, %1[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.insertvalue %arg9, %2[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.insertvalue %arg10, %3[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.insertvalue %arg12, %4[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.insertvalue %arg11, %5[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg13, %6[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.insertvalue %arg0, %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %arg1, %9[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg2, %10[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg3, %11[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.insertvalue %arg5, %12[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.insertvalue %arg4, %13[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg6, %14[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.mlir.constant(10 : index) : i64
    %17 = llvm.mlir.constant(5 : index) : i64
    %18 = llvm.mlir.constant(3 : index) : i64
    %19 = llvm.mlir.constant(1 : index) : i64
    %20 = llvm.mlir.constant(2 : index) : i64
    %21 = llvm.mlir.constant(0 : index) : i64
    %22 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %23 = llvm.mlir.constant(2 : index) : i64
    %24 = llvm.mlir.constant(3 : index) : i64
    %25 = llvm.mlir.constant(1 : index) : i64
    %26 = llvm.mlir.constant(6 : index) : i64
    %27 = llvm.mlir.zero : !llvm.ptr
    %28 = llvm.getelementptr %27[%26] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %29 = llvm.ptrtoint %28 : !llvm.ptr to i64
    %30 = llvm.mlir.constant(64 : index) : i64
    %31 = llvm.add %29, %30 : i64
    %32 = llvm.call @malloc(%31) : (i64) -> !llvm.ptr
    %33 = llvm.ptrtoint %32 : !llvm.ptr to i64
    %34 = llvm.mlir.constant(1 : index) : i64
    %35 = llvm.sub %30, %34 : i64
    %36 = llvm.add %33, %35 : i64
    %37 = llvm.urem %36, %30  : i64
    %38 = llvm.sub %36, %37 : i64
    %39 = llvm.inttoptr %38 : i64 to !llvm.ptr
    %40 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %41 = llvm.insertvalue %32, %40[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %42 = llvm.insertvalue %39, %41[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %43 = llvm.mlir.constant(0 : index) : i64
    %44 = llvm.insertvalue %43, %42[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %45 = llvm.insertvalue %23, %44[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %46 = llvm.insertvalue %24, %45[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %47 = llvm.insertvalue %24, %46[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %48 = llvm.insertvalue %25, %47[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.br ^bb1(%21 : i64)
  ^bb1(%49: i64):  // 2 preds: ^bb0, ^bb4
    %50 = llvm.icmp "slt" %49, %20 : i64
    llvm.cond_br %50, ^bb2(%21 : i64), ^bb5
  ^bb2(%51: i64):  // 2 preds: ^bb1, ^bb3
    %52 = llvm.icmp "slt" %51, %18 : i64
    llvm.cond_br %52, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %53 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %54 = llvm.mlir.constant(2 : index) : i64
    %55 = llvm.mul %51, %54 : i64
    %56 = llvm.add %55, %49 : i64
    %57 = llvm.getelementptr %53[%56] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %58 = llvm.load %57 : !llvm.ptr -> f32
    %59 = llvm.extractvalue %48[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %60 = llvm.mlir.constant(3 : index) : i64
    %61 = llvm.mul %49, %60 : i64
    %62 = llvm.add %61, %51 : i64
    %63 = llvm.getelementptr %59[%62] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %58, %63 : f32, !llvm.ptr
    %64 = llvm.add %51, %19 : i64
    llvm.br ^bb2(%64 : i64)
  ^bb4:  // pred: ^bb2
    %65 = llvm.add %49, %19 : i64
    llvm.br ^bb1(%65 : i64)
  ^bb5:  // pred: ^bb1
    %66 = llvm.extractvalue %15[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %67 = llvm.extractvalue %15[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %68 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64)>
    %69 = llvm.insertvalue %66, %68[0] : !llvm.struct<(ptr, ptr, i64)> 
    %70 = llvm.insertvalue %67, %69[1] : !llvm.struct<(ptr, ptr, i64)> 
    %71 = llvm.mlir.constant(0 : index) : i64
    %72 = llvm.insertvalue %71, %70[2] : !llvm.struct<(ptr, ptr, i64)> 
    %73 = llvm.extractvalue %15[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %74 = llvm.extractvalue %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %75 = llvm.extractvalue %15[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %76 = llvm.extractvalue %15[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %77 = llvm.extractvalue %15[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %78 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)>
    %79 = llvm.extractvalue %72[0] : !llvm.struct<(ptr, ptr, i64)> 
    %80 = llvm.extractvalue %72[1] : !llvm.struct<(ptr, ptr, i64)> 
    %81 = llvm.insertvalue %79, %78[0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %82 = llvm.insertvalue %80, %81[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %83 = llvm.insertvalue %21, %82[2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %84 = llvm.mlir.constant(1 : index) : i64
    %85 = llvm.insertvalue %84, %83[3, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %86 = llvm.insertvalue %16, %85[4, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %87 = llvm.mlir.constant(5 : index) : i64
    %88 = llvm.insertvalue %87, %86[3, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %89 = llvm.insertvalue %20, %88[4, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %90 = llvm.mlir.constant(2 : index) : i64
    %91 = llvm.insertvalue %90, %89[3, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %92 = llvm.insertvalue %19, %91[4, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %93 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)>
    %94 = llvm.extractvalue %48[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %95 = llvm.extractvalue %48[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %96 = llvm.insertvalue %94, %93[0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %97 = llvm.insertvalue %95, %96[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %98 = llvm.mlir.constant(0 : index) : i64
    %99 = llvm.insertvalue %98, %97[2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %100 = llvm.mlir.constant(1 : index) : i64
    %101 = llvm.insertvalue %100, %99[3, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %102 = llvm.mlir.constant(6 : index) : i64
    %103 = llvm.insertvalue %102, %101[4, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %104 = llvm.mlir.constant(2 : index) : i64
    %105 = llvm.insertvalue %104, %103[3, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %106 = llvm.mlir.constant(3 : index) : i64
    %107 = llvm.insertvalue %106, %105[4, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %108 = llvm.mlir.constant(3 : index) : i64
    %109 = llvm.insertvalue %108, %107[3, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %110 = llvm.mlir.constant(1 : index) : i64
    %111 = llvm.insertvalue %110, %109[4, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %112 = llvm.mlir.constant(1 : index) : i64
    %113 = llvm.mlir.constant(5 : index) : i64
    %114 = llvm.mlir.constant(3 : index) : i64
    %115 = llvm.mlir.constant(1 : index) : i64
    %116 = llvm.mlir.constant(15 : index) : i64
    %117 = llvm.mlir.constant(15 : index) : i64
    %118 = llvm.mlir.zero : !llvm.ptr
    %119 = llvm.getelementptr %118[%117] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %120 = llvm.ptrtoint %119 : !llvm.ptr to i64
    %121 = llvm.mlir.constant(64 : index) : i64
    %122 = llvm.add %120, %121 : i64
    %123 = llvm.call @malloc(%122) : (i64) -> !llvm.ptr
    %124 = llvm.ptrtoint %123 : !llvm.ptr to i64
    %125 = llvm.mlir.constant(1 : index) : i64
    %126 = llvm.sub %121, %125 : i64
    %127 = llvm.add %124, %126 : i64
    %128 = llvm.urem %127, %121  : i64
    %129 = llvm.sub %127, %128 : i64
    %130 = llvm.inttoptr %129 : i64 to !llvm.ptr
    %131 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)>
    %132 = llvm.insertvalue %123, %131[0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %133 = llvm.insertvalue %130, %132[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %134 = llvm.mlir.constant(0 : index) : i64
    %135 = llvm.insertvalue %134, %133[2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %136 = llvm.insertvalue %112, %135[3, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %137 = llvm.insertvalue %113, %136[3, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %138 = llvm.insertvalue %114, %137[3, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %139 = llvm.insertvalue %116, %138[4, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %140 = llvm.insertvalue %114, %139[4, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %141 = llvm.insertvalue %115, %140[4, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    llvm.br ^bb6(%21 : i64)
  ^bb6(%142: i64):  // 2 preds: ^bb5, ^bb11
    %143 = llvm.icmp "slt" %142, %19 : i64
    llvm.cond_br %143, ^bb7(%21 : i64), ^bb12(%21 : i64)
  ^bb7(%144: i64):  // 2 preds: ^bb6, ^bb10
    %145 = llvm.icmp "slt" %144, %17 : i64
    llvm.cond_br %145, ^bb8(%21 : i64), ^bb11
  ^bb8(%146: i64):  // 2 preds: ^bb7, ^bb9
    %147 = llvm.icmp "slt" %146, %18 : i64
    llvm.cond_br %147, ^bb9, ^bb10
  ^bb9:  // pred: ^bb8
    %148 = llvm.extractvalue %141[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %149 = llvm.mlir.constant(15 : index) : i64
    %150 = llvm.mul %142, %149 : i64
    %151 = llvm.mlir.constant(3 : index) : i64
    %152 = llvm.mul %144, %151 : i64
    %153 = llvm.add %150, %152 : i64
    %154 = llvm.add %153, %146 : i64
    %155 = llvm.getelementptr %148[%154] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %22, %155 : f32, !llvm.ptr
    %156 = llvm.add %146, %19 : i64
    llvm.br ^bb8(%156 : i64)
  ^bb10:  // pred: ^bb8
    %157 = llvm.add %144, %19 : i64
    llvm.br ^bb7(%157 : i64)
  ^bb11:  // pred: ^bb7
    %158 = llvm.add %142, %19 : i64
    llvm.br ^bb6(%158 : i64)
  ^bb12(%159: i64):  // 2 preds: ^bb6, ^bb19
    %160 = llvm.icmp "slt" %159, %19 : i64
    llvm.cond_br %160, ^bb13(%21 : i64), ^bb20
  ^bb13(%161: i64):  // 2 preds: ^bb12, ^bb18
    %162 = llvm.icmp "slt" %161, %17 : i64
    llvm.cond_br %162, ^bb14(%21 : i64), ^bb19
  ^bb14(%163: i64):  // 2 preds: ^bb13, ^bb17
    %164 = llvm.icmp "slt" %163, %18 : i64
    llvm.cond_br %164, ^bb15(%21 : i64), ^bb18
  ^bb15(%165: i64):  // 2 preds: ^bb14, ^bb16
    %166 = llvm.icmp "slt" %165, %20 : i64
    llvm.cond_br %166, ^bb16, ^bb17
  ^bb16:  // pred: ^bb15
    %167 = llvm.extractvalue %92[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %168 = llvm.extractvalue %92[2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %169 = llvm.getelementptr %167[%168] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %170 = llvm.extractvalue %92[4, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %171 = llvm.mul %159, %170 : i64
    %172 = llvm.extractvalue %92[4, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %173 = llvm.mul %161, %172 : i64
    %174 = llvm.add %171, %173 : i64
    %175 = llvm.extractvalue %92[4, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %176 = llvm.mul %165, %175 : i64
    %177 = llvm.add %174, %176 : i64
    %178 = llvm.getelementptr %169[%177] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %179 = llvm.load %178 : !llvm.ptr -> f32
    %180 = llvm.extractvalue %111[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %181 = llvm.mlir.constant(6 : index) : i64
    %182 = llvm.mul %159, %181 : i64
    %183 = llvm.mlir.constant(3 : index) : i64
    %184 = llvm.mul %165, %183 : i64
    %185 = llvm.add %182, %184 : i64
    %186 = llvm.add %185, %163 : i64
    %187 = llvm.getelementptr %180[%186] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %188 = llvm.load %187 : !llvm.ptr -> f32
    %189 = llvm.extractvalue %141[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %190 = llvm.mlir.constant(15 : index) : i64
    %191 = llvm.mul %159, %190 : i64
    %192 = llvm.mlir.constant(3 : index) : i64
    %193 = llvm.mul %161, %192 : i64
    %194 = llvm.add %191, %193 : i64
    %195 = llvm.add %194, %163 : i64
    %196 = llvm.getelementptr %189[%195] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %197 = llvm.load %196 : !llvm.ptr -> f32
    %198 = llvm.fmul %179, %188  : f32
    %199 = llvm.fadd %197, %198  : f32
    %200 = llvm.extractvalue %141[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %201 = llvm.mlir.constant(15 : index) : i64
    %202 = llvm.mul %159, %201 : i64
    %203 = llvm.mlir.constant(3 : index) : i64
    %204 = llvm.mul %161, %203 : i64
    %205 = llvm.add %202, %204 : i64
    %206 = llvm.add %205, %163 : i64
    %207 = llvm.getelementptr %200[%206] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %199, %207 : f32, !llvm.ptr
    %208 = llvm.add %165, %19 : i64
    llvm.br ^bb15(%208 : i64)
  ^bb17:  // pred: ^bb15
    %209 = llvm.add %163, %19 : i64
    llvm.br ^bb14(%209 : i64)
  ^bb18:  // pred: ^bb14
    %210 = llvm.add %161, %19 : i64
    llvm.br ^bb13(%210 : i64)
  ^bb19:  // pred: ^bb13
    %211 = llvm.add %159, %19 : i64
    llvm.br ^bb12(%211 : i64)
  ^bb20:  // pred: ^bb12
    %212 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %213 = llvm.extractvalue %141[0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %214 = llvm.extractvalue %141[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %215 = llvm.insertvalue %213, %212[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %216 = llvm.insertvalue %214, %215[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %217 = llvm.mlir.constant(0 : index) : i64
    %218 = llvm.insertvalue %217, %216[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %219 = llvm.mlir.constant(5 : index) : i64
    %220 = llvm.insertvalue %219, %218[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %221 = llvm.mlir.constant(3 : index) : i64
    %222 = llvm.insertvalue %221, %220[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %223 = llvm.mlir.constant(3 : index) : i64
    %224 = llvm.insertvalue %223, %222[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %225 = llvm.mlir.constant(1 : index) : i64
    %226 = llvm.insertvalue %225, %224[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.return %226 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
  }
  llvm.func @_mlir_ciface_test_linear(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.call @test_linear(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    llvm.store %16, %arg0 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>, !llvm.ptr
    llvm.return
  }
}


module {
  llvm.func @malloc(i64) -> !llvm.ptr
  llvm.mlir.global private constant @__constant_2xi32(dense<[1, 0]> : tensor<2xi32>) {addr_space = 0 : i32, alignment = 64 : i64} : !llvm.array<2 x i32>
  llvm.func @test_linear(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: i64, %arg3: i64, %arg4: i64, %arg5: i64, %arg6: i64, %arg7: !llvm.ptr, %arg8: !llvm.ptr, %arg9: i64, %arg10: i64, %arg11: i64, %arg12: i64, %arg13: i64) -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> attributes {llvm.emit_c_interface} {
    %0 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.insertvalue %arg7, %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.insertvalue %arg8, %1[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.insertvalue %arg9, %2[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.insertvalue %arg10, %3[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.insertvalue %arg12, %4[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.insertvalue %arg11, %5[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.insertvalue %arg13, %6[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.insertvalue %arg0, %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.insertvalue %arg1, %9[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.insertvalue %arg2, %10[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.insertvalue %arg3, %11[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.insertvalue %arg5, %12[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.insertvalue %arg4, %13[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.insertvalue %arg6, %14[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.mlir.constant(10 : index) : i64
    %17 = llvm.mlir.constant(5 : index) : i64
    %18 = llvm.mlir.constant(3 : index) : i64
    %19 = llvm.mlir.constant(1 : index) : i64
    %20 = llvm.mlir.constant(2 : index) : i64
    %21 = llvm.mlir.constant(0 : index) : i64
    %22 = llvm.mlir.constant(0.000000e+00 : f32) : f32
    %23 = llvm.mlir.constant(2 : index) : i64
    %24 = llvm.mlir.constant(3 : index) : i64
    %25 = llvm.mlir.constant(1 : index) : i64
    %26 = llvm.mlir.constant(6 : index) : i64
    %27 = llvm.mlir.zero : !llvm.ptr
    %28 = llvm.getelementptr %27[%26] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %29 = llvm.ptrtoint %28 : !llvm.ptr to i64
    %30 = llvm.mlir.constant(64 : index) : i64
    %31 = llvm.add %29, %30 : i64
    %32 = llvm.call @malloc(%31) : (i64) -> !llvm.ptr
    %33 = llvm.ptrtoint %32 : !llvm.ptr to i64
    %34 = llvm.mlir.constant(1 : index) : i64
    %35 = llvm.sub %30, %34 : i64
    %36 = llvm.add %33, %35 : i64
    %37 = llvm.urem %36, %30  : i64
    %38 = llvm.sub %36, %37 : i64
    %39 = llvm.inttoptr %38 : i64 to !llvm.ptr
    %40 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %41 = llvm.insertvalue %32, %40[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %42 = llvm.insertvalue %39, %41[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %43 = llvm.mlir.constant(0 : index) : i64
    %44 = llvm.insertvalue %43, %42[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %45 = llvm.insertvalue %23, %44[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %46 = llvm.insertvalue %24, %45[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %47 = llvm.insertvalue %24, %46[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %48 = llvm.insertvalue %25, %47[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.br ^bb1(%21 : i64)
  ^bb1(%49: i64):  // 2 preds: ^bb0, ^bb4
    %50 = llvm.icmp "slt" %49, %20 : i64
    llvm.cond_br %50, ^bb2(%21 : i64), ^bb5
  ^bb2(%51: i64):  // 2 preds: ^bb1, ^bb3
    %52 = llvm.icmp "slt" %51, %18 : i64
    llvm.cond_br %52, ^bb3, ^bb4
  ^bb3:  // pred: ^bb2
    %53 = llvm.extractvalue %7[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %54 = llvm.mlir.constant(2 : index) : i64
    %55 = llvm.mul %51, %54 : i64
    %56 = llvm.add %55, %49 : i64
    %57 = llvm.getelementptr %53[%56] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %58 = llvm.load %57 : !llvm.ptr -> f32
    %59 = llvm.extractvalue %48[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %60 = llvm.mlir.constant(3 : index) : i64
    %61 = llvm.mul %49, %60 : i64
    %62 = llvm.add %61, %51 : i64
    %63 = llvm.getelementptr %59[%62] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %58, %63 : f32, !llvm.ptr
    %64 = llvm.add %51, %19 : i64
    llvm.br ^bb2(%64 : i64)
  ^bb4:  // pred: ^bb2
    %65 = llvm.add %49, %19 : i64
    llvm.br ^bb1(%65 : i64)
  ^bb5:  // pred: ^bb1
    %66 = llvm.extractvalue %15[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %67 = llvm.extractvalue %15[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %68 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64)>
    %69 = llvm.insertvalue %66, %68[0] : !llvm.struct<(ptr, ptr, i64)> 
    %70 = llvm.insertvalue %67, %69[1] : !llvm.struct<(ptr, ptr, i64)> 
    %71 = llvm.mlir.constant(0 : index) : i64
    %72 = llvm.insertvalue %71, %70[2] : !llvm.struct<(ptr, ptr, i64)> 
    %73 = llvm.extractvalue %15[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %74 = llvm.extractvalue %15[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %75 = llvm.extractvalue %15[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %76 = llvm.extractvalue %15[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %77 = llvm.extractvalue %15[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %78 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)>
    %79 = llvm.extractvalue %72[0] : !llvm.struct<(ptr, ptr, i64)> 
    %80 = llvm.extractvalue %72[1] : !llvm.struct<(ptr, ptr, i64)> 
    %81 = llvm.insertvalue %79, %78[0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %82 = llvm.insertvalue %80, %81[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %83 = llvm.insertvalue %21, %82[2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %84 = llvm.mlir.constant(1 : index) : i64
    %85 = llvm.insertvalue %84, %83[3, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %86 = llvm.insertvalue %16, %85[4, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %87 = llvm.mlir.constant(5 : index) : i64
    %88 = llvm.insertvalue %87, %86[3, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %89 = llvm.insertvalue %20, %88[4, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %90 = llvm.mlir.constant(2 : index) : i64
    %91 = llvm.insertvalue %90, %89[3, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %92 = llvm.insertvalue %19, %91[4, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %93 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)>
    %94 = llvm.extractvalue %48[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %95 = llvm.extractvalue %48[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %96 = llvm.insertvalue %94, %93[0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %97 = llvm.insertvalue %95, %96[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %98 = llvm.mlir.constant(0 : index) : i64
    %99 = llvm.insertvalue %98, %97[2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %100 = llvm.mlir.constant(1 : index) : i64
    %101 = llvm.insertvalue %100, %99[3, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %102 = llvm.mlir.constant(6 : index) : i64
    %103 = llvm.insertvalue %102, %101[4, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %104 = llvm.mlir.constant(2 : index) : i64
    %105 = llvm.insertvalue %104, %103[3, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %106 = llvm.mlir.constant(3 : index) : i64
    %107 = llvm.insertvalue %106, %105[4, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %108 = llvm.mlir.constant(3 : index) : i64
    %109 = llvm.insertvalue %108, %107[3, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %110 = llvm.mlir.constant(1 : index) : i64
    %111 = llvm.insertvalue %110, %109[4, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %112 = llvm.mlir.constant(1 : index) : i64
    %113 = llvm.mlir.constant(5 : index) : i64
    %114 = llvm.mlir.constant(3 : index) : i64
    %115 = llvm.mlir.constant(1 : index) : i64
    %116 = llvm.mlir.constant(15 : index) : i64
    %117 = llvm.mlir.constant(15 : index) : i64
    %118 = llvm.mlir.zero : !llvm.ptr
    %119 = llvm.getelementptr %118[%117] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %120 = llvm.ptrtoint %119 : !llvm.ptr to i64
    %121 = llvm.mlir.constant(64 : index) : i64
    %122 = llvm.add %120, %121 : i64
    %123 = llvm.call @malloc(%122) : (i64) -> !llvm.ptr
    %124 = llvm.ptrtoint %123 : !llvm.ptr to i64
    %125 = llvm.mlir.constant(1 : index) : i64
    %126 = llvm.sub %121, %125 : i64
    %127 = llvm.add %124, %126 : i64
    %128 = llvm.urem %127, %121  : i64
    %129 = llvm.sub %127, %128 : i64
    %130 = llvm.inttoptr %129 : i64 to !llvm.ptr
    %131 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)>
    %132 = llvm.insertvalue %123, %131[0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %133 = llvm.insertvalue %130, %132[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %134 = llvm.mlir.constant(0 : index) : i64
    %135 = llvm.insertvalue %134, %133[2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %136 = llvm.insertvalue %112, %135[3, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %137 = llvm.insertvalue %113, %136[3, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %138 = llvm.insertvalue %114, %137[3, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %139 = llvm.insertvalue %116, %138[4, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %140 = llvm.insertvalue %114, %139[4, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %141 = llvm.insertvalue %115, %140[4, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    llvm.br ^bb6(%21 : i64)
  ^bb6(%142: i64):  // 2 preds: ^bb5, ^bb11
    %143 = llvm.icmp "slt" %142, %19 : i64
    llvm.cond_br %143, ^bb7(%21 : i64), ^bb12(%21 : i64)
  ^bb7(%144: i64):  // 2 preds: ^bb6, ^bb10
    %145 = llvm.icmp "slt" %144, %17 : i64
    llvm.cond_br %145, ^bb8(%21 : i64), ^bb11
  ^bb8(%146: i64):  // 2 preds: ^bb7, ^bb9
    %147 = llvm.icmp "slt" %146, %18 : i64
    llvm.cond_br %147, ^bb9, ^bb10
  ^bb9:  // pred: ^bb8
    %148 = llvm.extractvalue %141[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %149 = llvm.mlir.constant(15 : index) : i64
    %150 = llvm.mul %142, %149 : i64
    %151 = llvm.mlir.constant(3 : index) : i64
    %152 = llvm.mul %144, %151 : i64
    %153 = llvm.add %150, %152 : i64
    %154 = llvm.add %153, %146 : i64
    %155 = llvm.getelementptr %148[%154] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %22, %155 : f32, !llvm.ptr
    %156 = llvm.add %146, %19 : i64
    llvm.br ^bb8(%156 : i64)
  ^bb10:  // pred: ^bb8
    %157 = llvm.add %144, %19 : i64
    llvm.br ^bb7(%157 : i64)
  ^bb11:  // pred: ^bb7
    %158 = llvm.add %142, %19 : i64
    llvm.br ^bb6(%158 : i64)
  ^bb12(%159: i64):  // 2 preds: ^bb6, ^bb19
    %160 = llvm.icmp "slt" %159, %19 : i64
    llvm.cond_br %160, ^bb13(%21 : i64), ^bb20
  ^bb13(%161: i64):  // 2 preds: ^bb12, ^bb18
    %162 = llvm.icmp "slt" %161, %17 : i64
    llvm.cond_br %162, ^bb14(%21 : i64), ^bb19
  ^bb14(%163: i64):  // 2 preds: ^bb13, ^bb17
    %164 = llvm.icmp "slt" %163, %18 : i64
    llvm.cond_br %164, ^bb15(%21 : i64), ^bb18
  ^bb15(%165: i64):  // 2 preds: ^bb14, ^bb16
    %166 = llvm.icmp "slt" %165, %20 : i64
    llvm.cond_br %166, ^bb16, ^bb17
  ^bb16:  // pred: ^bb15
    %167 = llvm.extractvalue %92[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %168 = llvm.extractvalue %92[2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %169 = llvm.getelementptr %167[%168] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %170 = llvm.extractvalue %92[4, 0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %171 = llvm.mul %159, %170 : i64
    %172 = llvm.extractvalue %92[4, 1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %173 = llvm.mul %161, %172 : i64
    %174 = llvm.add %171, %173 : i64
    %175 = llvm.extractvalue %92[4, 2] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %176 = llvm.mul %165, %175 : i64
    %177 = llvm.add %174, %176 : i64
    %178 = llvm.getelementptr %169[%177] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %179 = llvm.load %178 : !llvm.ptr -> f32
    %180 = llvm.extractvalue %111[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %181 = llvm.mlir.constant(6 : index) : i64
    %182 = llvm.mul %159, %181 : i64
    %183 = llvm.mlir.constant(3 : index) : i64
    %184 = llvm.mul %165, %183 : i64
    %185 = llvm.add %182, %184 : i64
    %186 = llvm.add %185, %163 : i64
    %187 = llvm.getelementptr %180[%186] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %188 = llvm.load %187 : !llvm.ptr -> f32
    %189 = llvm.extractvalue %141[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %190 = llvm.mlir.constant(15 : index) : i64
    %191 = llvm.mul %159, %190 : i64
    %192 = llvm.mlir.constant(3 : index) : i64
    %193 = llvm.mul %161, %192 : i64
    %194 = llvm.add %191, %193 : i64
    %195 = llvm.add %194, %163 : i64
    %196 = llvm.getelementptr %189[%195] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    %197 = llvm.load %196 : !llvm.ptr -> f32
    %198 = llvm.fmul %179, %188  : f32
    %199 = llvm.fadd %197, %198  : f32
    %200 = llvm.extractvalue %141[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %201 = llvm.mlir.constant(15 : index) : i64
    %202 = llvm.mul %159, %201 : i64
    %203 = llvm.mlir.constant(3 : index) : i64
    %204 = llvm.mul %161, %203 : i64
    %205 = llvm.add %202, %204 : i64
    %206 = llvm.add %205, %163 : i64
    %207 = llvm.getelementptr %200[%206] : (!llvm.ptr, i64) -> !llvm.ptr, f32
    llvm.store %199, %207 : f32, !llvm.ptr
    %208 = llvm.add %165, %19 : i64
    llvm.br ^bb15(%208 : i64)
  ^bb17:  // pred: ^bb15
    %209 = llvm.add %163, %19 : i64
    llvm.br ^bb14(%209 : i64)
  ^bb18:  // pred: ^bb14
    %210 = llvm.add %161, %19 : i64
    llvm.br ^bb13(%210 : i64)
  ^bb19:  // pred: ^bb13
    %211 = llvm.add %159, %19 : i64
    llvm.br ^bb12(%211 : i64)
  ^bb20:  // pred: ^bb12
    %212 = llvm.mlir.undef : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %213 = llvm.extractvalue %141[0] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %214 = llvm.extractvalue %141[1] : !llvm.struct<(ptr, ptr, i64, array<3 x i64>, array<3 x i64>)> 
    %215 = llvm.insertvalue %213, %212[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %216 = llvm.insertvalue %214, %215[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %217 = llvm.mlir.constant(0 : index) : i64
    %218 = llvm.insertvalue %217, %216[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %219 = llvm.mlir.constant(5 : index) : i64
    %220 = llvm.insertvalue %219, %218[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %221 = llvm.mlir.constant(3 : index) : i64
    %222 = llvm.insertvalue %221, %220[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %223 = llvm.mlir.constant(3 : index) : i64
    %224 = llvm.insertvalue %223, %222[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %225 = llvm.mlir.constant(1 : index) : i64
    %226 = llvm.insertvalue %225, %224[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    llvm.return %226 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
  }
  llvm.func @_mlir_ciface_test_linear(%arg0: !llvm.ptr, %arg1: !llvm.ptr, %arg2: !llvm.ptr) attributes {llvm.emit_c_interface} {
    %0 = llvm.load %arg1 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %1 = llvm.extractvalue %0[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %2 = llvm.extractvalue %0[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %3 = llvm.extractvalue %0[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %4 = llvm.extractvalue %0[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %5 = llvm.extractvalue %0[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %6 = llvm.extractvalue %0[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %7 = llvm.extractvalue %0[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %8 = llvm.load %arg2 : !llvm.ptr -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    %9 = llvm.extractvalue %8[0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %10 = llvm.extractvalue %8[1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %11 = llvm.extractvalue %8[2] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %12 = llvm.extractvalue %8[3, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %13 = llvm.extractvalue %8[3, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %14 = llvm.extractvalue %8[4, 0] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %15 = llvm.extractvalue %8[4, 1] : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)> 
    %16 = llvm.call @test_linear(%1, %2, %3, %4, %5, %6, %7, %9, %10, %11, %12, %13, %14, %15) : (!llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64, !llvm.ptr, !llvm.ptr, i64, i64, i64, i64, i64) -> !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>
    llvm.store %16, %arg0 : !llvm.struct<(ptr, ptr, i64, array<2 x i64>, array<2 x i64>)>, !llvm.ptr
    llvm.return
  }
}
